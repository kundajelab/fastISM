{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846a3dd3-3a20-4727-946c-0b831d996094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import fastISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03c81fc-a5a2-4bfc-a3b0-1d861849f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  1 00:38:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    52W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243c2dfd-9130-4bb0-a2ce-bb72c6c345ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: A100-SXM4-40GB (UUID: GPU-b593d456-e6a0-80b7-b80e-c06dab2dca6a)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e8238a-4cc5-4251-8446-73b8bd36219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.109\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8c98e7-07f4-4c99-87e5-d33c54acaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test seqs (randomly sampled from hg38 chr1-22)\n",
    "# !wget http://mitra.stanford.edu/kundaje/surag/fastISM/test_long.seq.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166f7e92-cb0f-4e0d-9bba-e23d2b9fafe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 196608, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = np.load(\"test_long.seq.npy\")\n",
    "seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792702f-01dc-40bc-9065-9fcc9b11c386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca12cb0f-f29c-4d2c-927c-f55a2005c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ism(ism_model, batch_sizes, seqlen):\n",
    "    times = []\n",
    "    per_100 = []\n",
    "    for b in batch_sizes:\n",
    "        assert(b <= seqs.shape[0])\n",
    "        # dry run -- required as first batch slower for setting up\n",
    "        #            and variable batch sizes (due to varying number\n",
    "        #            of seqs that need to be mutated at a position) \n",
    "        #            also slows down first call\n",
    "        # x = np.random.random((b,seqlen,4))\n",
    "        x = seqs[:b, :seqlen]        \n",
    "        x = tf.constant(x, dtype=ism_model.model.inputs[0].dtype)\n",
    "        o = ism_model(x, [0,0,0,1])\n",
    "        \n",
    "        t = time.time()\n",
    "        x = tf.constant(x, dtype=ism_model.model.inputs[0].dtype)\n",
    "        \n",
    "        # NOTE: computations are only performed at those positions\n",
    "        # at which the existing base != replace_with\n",
    "        o = ism_model(x, replace_with=[0,0,0,1])\n",
    "        o = ism_model(x, replace_with=[0,0,1,0])\n",
    "        o = ism_model(x, replace_with=[0,1,0,0])\n",
    "        o = ism_model(x, replace_with=[1,0,0,0])\n",
    "        \n",
    "        times.append(time.time()-t)\n",
    "        \n",
    "        per_100.append((times[-1]/b)*100)\n",
    "        print(\"BATCH: {}\\tTIME: {:.2f}\\tPER 100: {:.2f}\".format(b, times[-1], (times[-1]/b)*100))\n",
    "    \n",
    "    print(\"BEST PER 100: {:.2f}\".format(min(per_100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a870255-d455-4a87-8d75-8ef6a5552a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f11a32-3f89-4f16-bcab-587a380d2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from https://github.com/deepmind/deepmind-research/blob/master/enformer/enformer.py\n",
    "\n",
    "class AttentionPooling1D(tf.keras.layers.Layer):\n",
    "    \"\"\"Pooling operation with optional weights.\"\"\"\n",
    "    def __init__(self,\n",
    "            pool_size: int = 2,\n",
    "            per_channel: bool = True,\n",
    "            w_init_scale: float = 2.0,\n",
    "                **kwargs):\n",
    "        \"\"\"Softmax pooling.\n",
    "        Args:\n",
    "        pool_size: Pooling size, same as in Max/AvgPooling.\n",
    "        per_channel: If True, the logits/softmax weights will be computed for\n",
    "        each channel separately. If False, same weights will be used across all\n",
    "        channels.\n",
    "         w_init_scale: When 0.0 is equivalent to avg pooling, and when\n",
    "        ~2.0 and `per_channel=False` it's equivalent to max pooling.\n",
    "        name: Module name.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self._per_channel = per_channel\n",
    "        self._w_init_scale = w_init_scale\n",
    "        self._logit_linear = None\n",
    "        \n",
    "        # need for pooling layer\n",
    "        self.strides = self.pool_size \n",
    "        self.padding = \"valid\" # here we are using padding of 2 on multiples of 2 so it's ok\n",
    "        self.data_format = \"channels_last\"\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, num_features = input_shape\n",
    "        self.w = self.add_weight(\n",
    "            shape=(num_features, num_features),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        # self._logit_linear = tf.keras.layers.Dense(\n",
    "        # output_size=num_features if self._per_channel else 1,\n",
    "        # with_bias=False,  # Softmax is agnostic to shifts.\n",
    "        # w_init=snt.initializers.Identity(self._w_init_scale))\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"pool_size\": self.pool_size,\n",
    "            \"_per_channel\": self._per_channel,\n",
    "            \"_w_init_scale\": self._w_init_scale,\n",
    "            \"_logit_linear\": self._logit_linear,\n",
    "            \"data_format\": self.data_format,\n",
    "            \"strides\": self.strides,\n",
    "            \"padding\": self.padding\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @tf.function(jit_compile=True)\n",
    "    def call(self, inputs):\n",
    "        _, length, num_features = inputs.shape\n",
    "        \n",
    "        if length == None: # this can happen at when creating fast_ism_model\n",
    "            return inputs # don't do anything for now\n",
    "            \n",
    "        inputs = tf.reshape(\n",
    "            inputs,\n",
    "            (-1, length // self.pool_size, self.pool_size, num_features))\n",
    "        # return tf.reduce_sum(\n",
    "        #     inputs * tf.nn.softmax(self._logit_linear(inputs), axis=-2),\n",
    "        #     axis=-2)\n",
    "        return tf.reduce_sum(\n",
    "            inputs * tf.nn.softmax(tf.matmul(inputs, self.w), axis=-2),\n",
    "            axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4946e195-81c9-4340-b113-7831dcf67d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointwiseResConv(keras.layers.Layer):\n",
    "    # point-wise convolution residual layer -- essentially see-through\n",
    "    def __init__(self, c, **kwargs):\n",
    "        super(PointwiseResConv, self).__init__()\n",
    "        self.c = c\n",
    "        self.bn = keras.layers.BatchNormalization()        \n",
    "        self.act = keras.layers.Activation('gelu')        \n",
    "        self.conv = keras.layers.Conv1D(self.c, 1)        \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"c\": self.c,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.bn(inputs)\n",
    "        x = self.act(x)\n",
    "        x = self.conv(x)\n",
    "        x = keras.layers.Add()([x,inputs])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3a8376-5b19-4ed3-839b-3cc8b9a1de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(c, w, padding, x_input):\n",
    "    x = keras.layers.BatchNormalization()(x_input)\n",
    "    x = keras.layers.Activation('gelu')(x)\n",
    "    x = keras.layers.Conv1D(c,w, padding=padding)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def enformer(inlen=196608, C=1536, num_conv=6, num_tx=11, crop_each=320, out_dim=5313):\n",
    "    inp = keras.layers.Input((inlen,4))\n",
    "    \n",
    "    x = keras.layers.Conv1D(C//2, 15, padding='same')(inp)\n",
    "    x = PointwiseResConv(C//2)(x)\n",
    "    x = AttentionPooling1D(2, True)(x)\n",
    "    \n",
    "    tower_chans = [int((C//2)*(2**(1/num_conv))**i) for i in range(1,num_conv+1)]\n",
    "    for ci in tower_chans:\n",
    "        x = conv_block(ci, 5, 'same', x)\n",
    "        x = PointwiseResConv(ci)(x)\n",
    "        x = AttentionPooling1D(2, True)(x)\n",
    "    \n",
    "    # just an identity layer, using this as STOP_LAYER\n",
    "    # there's an edge case that needs to be taken care of\n",
    "    # when the stop layer is within a branch\n",
    "    x = keras.layers.Layer()(x)\n",
    "    \n",
    "    for i in range(num_tx):\n",
    "        y = keras.layers.LayerNormalization()(x)\n",
    "        \n",
    "        # using more heads than that in paper \n",
    "        # this is because keras MHA doesn't apply positional \n",
    "        # encoding, so increasing number of heads here matches\n",
    "        # the time taken by DeepMind's MHA block (timed separately, not shown here)\n",
    "        y = keras.layers.MultiHeadAttention(20, 64, C//8)(y, y)\n",
    "        x = keras.layers.Add()([x,y])\n",
    "        \n",
    "        y = keras.layers.LayerNormalization()(x)\n",
    "        y = keras.layers.Dense(C*2, activation='relu')(y)\n",
    "        y = keras.layers.Dense(C)(y)\n",
    "        x = keras.layers.Add()([x,y])\n",
    "        x=y\n",
    "\n",
    "    if crop_each>0:\n",
    "        x = keras.layers.Cropping1D(crop_each)(x)\n",
    "        \n",
    "    x = conv_block(C*2, 1, 'valid', x)\n",
    "    x = keras.layers.Activation('gelu')(x)\n",
    "    \n",
    "    x = keras.layers.Conv1D(out_dim, 1, padding='valid', activation='softplus')(x)\n",
    "\n",
    "    m = keras.Model(inputs=inp, outputs=x)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3c5ea-b9ca-4095-86d7-c227381869c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d586141-e859-4112-80c8-3a0373c74837",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastISM.fast_ism_utils.POOLING_LAYERS.add(\"AttentionPooling1D\")\n",
    "fastISM.fast_ism_utils.STOP_LAYERS.add(\"Layer\")\n",
    "fastISM.fast_ism_utils.SEE_THROUGH_LAYERS.add(\"PointwiseResConv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e42c2a7-94e7-47a8-a61c-91fea1916487",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821e0baf-2f61-4220-8364-fcdc2f1c1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 21:42:34.532956: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-04 21:42:35.042297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38444 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = enformer(out_dim=5313, num_tx=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e31944-f2e5-42b4-840d-8117772e5b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354722383"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2de788-8262-4d70-a97d-fd8c87e7b731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0775aae-aa17-44e1-b601-1ec2d4e09197",
   "metadata": {},
   "outputs": [],
   "source": [
    "loltf = tf.constant(np.random.random((1000,196608,4)), dtype=model.input.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86e51be-54e3-4377-9c03-b36a7ec4526b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 21:42:47.907581: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-02-04 21:42:49.820850: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-02-04 21:42:49.884603: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55b0b21d5ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-04 21:42:49.884641: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): A100-SXM4-40GB, Compute Capability 8.0\n",
      "2022-02-04 21:42:49.891528: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-02-04 21:42:55.382691: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function AttentionPooling1D.call at 0x7fcd2e4663b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AttentionPooling1D.call at 0x7fcd2c0eac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 896, 5313)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff167c9-27e7-47b7-a896-9e9670fec278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e539b7-fe65-42cb-ae2b-a9c7746db885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680 ms ± 1.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d645bb4e-df92-436a-8346-5dda260a6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 s ± 1.09 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(loltf[:7], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d7912-8795-4988-8542-9e6d24a23937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94386482-5724-4a45-b87a-521299172196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce5b29ca-7507-4ead-95a8-dc102e454699",
   "metadata": {},
   "source": [
    "**Scoring 100bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde87a3a-8a51-4f76-9f37-39630ace06cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_ism_model = fastISM.FastISM(model,\n",
    "                                 test_correctness=False, \n",
    "                                 change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2-50, model.input_shape[1]//2 + 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4b1e490-eeb0-474a-8f5e-87fe91849faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 10\tTIME: 164.15\tPER 100: 1641.52\n",
      "BEST PER 100: 1641.52\n"
     ]
    }
   ],
   "source": [
    "time_ism(fast_ism_model, [10], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0874ab9-6296-4762-92d9-502d23641b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c8fdaa6-8179-476f-ab29-c069082c60bf",
   "metadata": {},
   "source": [
    "**Scoring 100bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7694e10e-e501-48d9-87ae-ac44dfe6c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_ism_model = fastISM.NaiveISM(model, change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2-50, model.input_shape[1]//2 + 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82430c5b-507c-48a0-9bd3-33e879abd264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 6\tTIME: 227.50\tPER 100: 3791.72\n",
      "BATCH: 5\tTIME: 197.11\tPER 100: 3942.30\n",
      "BATCH: 7\tTIME: 281.97\tPER 100: 4028.08\n",
      "BEST PER 100: 3791.72\n"
     ]
    }
   ],
   "source": [
    "time_ism(naive_ism_model, [6,5,7], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2240e3b-2093-4c19-a3d3-e95afea47920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29abc721-f81d-4b2b-a61a-4c2aabcef674",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Full Enformer, Small output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c74c6c-a327-46d9-880f-f2b80109de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 22:55:58.212698: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-04 22:55:58.728247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38444 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = enformer(out_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae00a5-b2e6-4396-b281-acc70cac8eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e6751a-b3f1-466c-bf5b-27c99c1654d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loltf = tf.constant(np.random.random((100,196608,4)), dtype=model.input.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbb0eae-c438-40a8-9d1c-508fef27a7b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 22:56:07.254938: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-02-04 22:56:09.189477: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-02-04 22:56:09.253316: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x55ccc643e6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-04 22:56:09.253353: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): A100-SXM4-40GB, Compute Capability 8.0\n",
      "2022-02-04 22:56:09.260807: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-02-04 22:56:14.762937: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function AttentionPooling1D.call at 0x7f086c0d73b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AttentionPooling1D.call at 0x7f086c066c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 896, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920c76d-786d-4667-b443-ff4fb42f885f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20aae283-e3a9-486e-b9ce-affb555aeb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 ms ± 449 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f496517-34d5-4618-964d-509fb58539bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904 ms ± 521 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(loltf[:7], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7ba98-e489-4467-9d16-4337b0757cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c9fcaf-da7d-49ca-9e45-e02e0fcc0b7e",
   "metadata": {},
   "source": [
    "**Scoring 1000bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6877a45a-2451-432d-9dfa-5eb8c0020067",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_ism_model = fastISM.FastISM(model, \n",
    "                                 test_correctness=False, \n",
    "                                 change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2-500, model.input_shape[1]//2 + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c13a22-2410-412f-b23f-f945ff9d3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 22:21:11.690892: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 11\tTIME: 1109.47\tPER 100: 10086.06\n",
      "BEST PER 100: 10086.06\n"
     ]
    }
   ],
   "source": [
    "time_ism(fast_ism_model, [11], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9e53a-af69-4f76-a159-1538dec55296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7bfedd-ab8a-4a29-9dc2-5f1c725f6472",
   "metadata": {},
   "source": [
    "**Scoring 100bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "706036bf-e0e0-4abf-99bc-ddc24d246f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_ism_model = fastISM.NaiveISM(model, \n",
    "                                   change_ranges=[(x,x+1) for x in \\\n",
    "                                                  range(model.input_shape[1]//2-50, \n",
    "                                                        model.input_shape[1]//2 + 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a4ac55-37cd-4d81-aacd-f4f8fb267507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 6\tTIME: 193.76\tPER 100: 3229.29\n",
      "BATCH: 5\tTIME: 168.71\tPER 100: 3374.21\n",
      "BEST PER 100: 3229.29\n"
     ]
    }
   ],
   "source": [
    "time_ism(naive_ism_model, [6,5], 196608)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ac7a6-187e-40a4-8e9a-4829d71f2279",
   "metadata": {},
   "source": [
    "**Scoring 1000bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc4a1d58-bdf1-4dbe-986e-45d29485d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_ism_model = fastISM.NaiveISM(model, \n",
    "                                   change_ranges=[(x,x+1) for x in \\\n",
    "                                                  range(model.input_shape[1]//2 - 500, \n",
    "                                                        model.input_shape[1]//2 + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a97e0b6f-0e6d-4ab5-b8c9-f220467b89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 6\tTIME: 1918.78\tPER 100: 31979.73\n",
      "BEST PER 100: 31979.73\n"
     ]
    }
   ],
   "source": [
    "time_ism(naive_ism_model, [6], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc700bcc-1ed0-4121-b9e2-9ddf660021ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a75df1c-7402-453d-afc6-d21539e04602",
   "metadata": {},
   "source": [
    "**Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416b7fb4-7364-4ea9-a480-cab2166c93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fism_out = fast_ism_model(loltf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa7b6be-8b65-453e-b991-b9663be52107",
   "metadata": {},
   "outputs": [],
   "source": [
    "nism_out = naive_ism_model(loltf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78e7129d-0006-4c37-9f63-7f29e492c97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(fism_out, nism_out, atol=1e-2)), np.all(np.isclose(nism_out, fism_out, atol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322b37be-92d8-494d-be5d-6daffb28a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99999921875, 0.99999921875)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(fism_out, nism_out, atol=1e-3)), np.mean(np.isclose(nism_out, fism_out, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c6f68c-e676-4bc1-bb04-af95cacb59be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44960645, 0.5226613 , 0.71340764, 0.76874745, 0.6769167 ,\n",
       "       0.7781925 , 0.88031006, 0.5711825 , 0.8310388 , 0.5729828 ,\n",
       "       0.73103267, 0.4928353 , 0.82416934, 0.52590275, 0.6440538 ,\n",
       "       0.71847594, 0.65493226, 0.89954627, 0.710739  , 0.525694  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fism_out[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b80b0f-87be-4c8b-9b13-91101eba4c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44960108, 0.5222728 , 0.71331096, 0.7684644 , 0.6770802 ,\n",
       "       0.77832896, 0.8805904 , 0.5711045 , 0.83050287, 0.57302916,\n",
       "       0.731101  , 0.49275845, 0.8243413 , 0.526146  , 0.6440768 ,\n",
       "       0.7184003 , 0.65477055, 0.89942145, 0.7109796 , 0.52549505],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nism_out[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef5a10b-e8de-46bc-a143-664c4eb61f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9999848592062245, pvalue=0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "scipy.stats.spearmanr(nism_out.ravel(), fism_out.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060db76-5b42-4135-8ea5-b7784528668a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e76222-13b4-47e1-887a-c7bb50b592e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enformer 4 Tx, small output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557cc5fd-adc5-44c7-a796-6449d9b66a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 23:41:49.507717: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-04 23:41:50.022467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38444 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = enformer(inlen=196608, C=1536, num_tx=4, crop_each=320, out_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d3c667-eb1b-470f-b5a4-6707329f3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "loltf = tf.constant(np.random.random((100,196608,4)), dtype=model.input.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9acdb4b-6cb9-4331-ad34-8d486d697ec7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 23:41:53.246607: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-02-04 23:41:55.201712: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-02-04 23:41:55.266975: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x556b3da73b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-04 23:41:55.267012: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): A100-SXM4-40GB, Compute Capability 8.0\n",
      "2022-02-04 23:41:55.274264: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-02-04 23:42:00.782316: I tensorflow/compiler/jit/xla_compilation_cache.cc:351] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function AttentionPooling1D.call at 0x7f18854bf8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AttentionPooling1D.call at 0x7f188413ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 896, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6d341-fb33-45c5-8fe2-15e232b07513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0745f5-4633-4e80-b793-b0060bac4ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 ms ± 636 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(loltf[:6], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cdc4b9-ec97-4a58-a84d-159b8c255e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790 ms ± 434 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# sudden jump, not sure why\n",
    "%timeit model(loltf[:7], training=False).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86cf25-9266-4852-853b-21db9b0d0a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5130fc88-2dda-4926-94fa-cdf53c288940",
   "metadata": {},
   "source": [
    "**Scoring 1000bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b9e436c-57c6-4a7d-ac0b-6d20f8ebe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_ism_model = fastISM.FastISM(model, test_correctness=False, \n",
    "                                 change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2 - 500, \n",
    "                                                                       model.input_shape[1]//2 + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8377f910-03b8-4cf1-9216-cea7efc60b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 23:43:11.845525: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 12\tTIME: 585.38\tPER 100: 4878.16\n",
      "BEST PER 100: 4878.16\n"
     ]
    }
   ],
   "source": [
    "time_ism(fast_ism_model, [12], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73b66d-324d-4b1d-a7fa-d32e5eb9fe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78625833-dd06-4861-9459-8894e0ccb5ab",
   "metadata": {},
   "source": [
    "**Scoring 100bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7c19d16-9d92-4e76-9500-78913983ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_ism_model = fastISM.NaiveISM(model, \n",
    "                                   change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2 - 50, \n",
    "                                                                         model.input_shape[1]//2 + 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f87e449-b0cf-4b3b-ab7f-573bfc17949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 6\tTIME: 161.99\tPER 100: 2699.83\n",
      "BATCH: 5\tTIME: 141.66\tPER 100: 2833.28\n",
      "BEST PER 100: 2699.83\n"
     ]
    }
   ],
   "source": [
    "time_ism(naive_ism_model, [6, 5], 196608)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea239ce-b43b-4409-a7f8-6fa676057afa",
   "metadata": {},
   "source": [
    "**Scoring 1000bp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87bc1cb9-f413-4942-85ae-1d494394da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_ism_model = fastISM.NaiveISM(model, \n",
    "                                   change_ranges=[(x,x+1) for x in range(model.input_shape[1]//2 - 500, \n",
    "                                                                         model.input_shape[1]//2 + 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79682242-dec6-4de5-81ef-02aee3f9ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 6\tTIME: 1601.63\tPER 100: 26693.76\n",
      "BEST PER 100: 26693.76\n"
     ]
    }
   ],
   "source": [
    "time_ism(naive_ism_model, [6], 196608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4886c94-587d-47a5-ba20-4ae262c0e7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7c70e-d6ab-44f2-a8b4-1f282bb5669a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
