{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise ISM for the Basset Architecture\n",
    "\n",
    "Experimental, trying to find the right way to do it for simple architectures.\n",
    "\n",
    "Architecture: [link](https://github.com/kundajelab/GenoPyT/blob/c84f38dfaa0c986f91383dd7e6278c1cb993498d/src/models/sequence_only/basset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs_conv_maxpool(seqlen, kernelsize, padding, maxpool_kernel, change_ranges, \n",
    "                          conv_stride=1,\n",
    "                          maxpool_stride=None,\n",
    "                          maxpool_ceil_mode=False): \n",
    "\n",
    "    # assumes stride==1 for conv and stride=kernel for maxpool \n",
    "    # change ranges are BEFORE padding \n",
    "    # indexes returned are slices AFTER padding input seqs\n",
    "    \n",
    "    if maxpool_ceil_mode==True or conv_stride!=1 or maxpool_stride!=None: \n",
    "        # will take extra care, e.g. repeat values in last block  \n",
    "        raise NotImplementedError \n",
    "     \n",
    "    # raw ranges for each change_range -- this is the input range in which\n",
    "    # changing the change_range will affect the output\n",
    "    raw_seq_ranges = [(x-kernelsize+1,y+kernelsize-1) for x,y in change_ranges] \n",
    "     \n",
    "    # re-adjust since there will be `padding` number of zeros in the beginning \n",
    "    raw_seq_pad_adjusted = [(x+padding, y+padding) for x,y in raw_seq_ranges] \n",
    "     \n",
    "    range_corrected = [] \n",
    "    for x,y in raw_seq_pad_adjusted: \n",
    "        # shift around the edges\n",
    "        if x<0 and y>seqlen+2*padding: # kinda degenerate, required when using for fc layers\n",
    "            range_corrected.append((0,seqlen+2*padding))\n",
    "        elif x<0: \n",
    "            range_corrected.append((0, y-x)) \n",
    "        elif y > seqlen+2*padding: \n",
    "            range_corrected.append((x-(y-seqlen-2*padding),seqlen+2*padding)) \n",
    "        else: \n",
    "            range_corrected.append((x,y)) \n",
    "\n",
    "    # the conv output range affected by each input\n",
    "    conv_out_ranges = [(x,y-kernelsize+1) for x,y in range_corrected] \n",
    "\n",
    "    # length of sequence after convolution\n",
    "    conv_seqlen = seqlen + 2*padding - kernelsize + 1\n",
    "    \n",
    "    # shift to the edges of the nearest maxpool block\n",
    "    mod_shifted = [(maxpool_kernel*(x//maxpool_kernel), \n",
    "                   maxpool_kernel*((y-1)//maxpool_kernel+1)) for x,y in conv_out_ranges] \n",
    "    # each should be the same size\n",
    "    maxwidth = max([y-x for x,y in mod_shifted])  \n",
    "\n",
    "    mod_shifted = [(x,x+maxwidth) if y<=conv_seqlen else (y-maxwidth, y) for x,y in mod_shifted]  \n",
    "     \n",
    "    # when ceil_mode==False, this works by ignoring last block [ceil_mode==False also ignores last block]  \n",
    "    mod_shifted = [(x,y) if y<=conv_seqlen else (x-maxpool_kernel,y-maxpool_kernel) for x,y in mod_shifted]  \n",
    "    assert([y<=conv_seqlen for _,y in mod_shifted])  \n",
    "    \n",
    "    # this would be the output ranges AFTER maxpool\n",
    "    out_ranges = [(x//maxpool_kernel, y//maxpool_kernel) for x,y in mod_shifted]  \n",
    "     \n",
    "    # work back input slices for desired output maxpool ranges\n",
    "    slice_ranges = [(x,y+kernelsize-1) for x,y in mod_shifted] \n",
    "    \n",
    "    offsets = [x+padding-slice_ranges[i][0] for i,(x,_) in enumerate(change_ranges)] \n",
    "    \n",
    "    return (slice_ranges, offsets), out_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "(s_slices, _), mxp1_out_ranges = get_idxs_conv_maxpool(1000, 19, 9, 3, [(i,i+1) for i in range(1000)])\n",
    "inp_width = s_slices[0][1]-s_slices[0][0]\n",
    "print(inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq = torch.rand(1, 4, 1000).cuda()\n",
    "inp_seq_perturbed = inp_seq.repeat(1000,1,1)\n",
    "inp_seq_perturbed[torch.arange(1000), :, torch.arange(1000)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq_slices = sum([list(range(*x)) for x in s_slices], [])\n",
    "inp_seq_slices = torch.tensor(inp_seq_slices).view(-1, inp_width)\n",
    "inp_seq_slices = inp_seq_slices.unsqueeze(1).repeat(1,4,1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 1000])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_perturbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 39])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_slices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inp_seq = torch.zeros(1000, 4, 1018).cuda()\n",
    "padded_inp_seq[:, :, 9:1009] = inp_seq_perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "#     padded_inp_seq = torch.zeros(1000, 4, 1018).cuda()\n",
    "    padded_inp_seq[:, :, 9:1009] = inp_seq_perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 µs ± 56.6 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9 µs ± 1.45 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.gather(padded_inp_seq, 2, inp_seq_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1 + Maxpool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(layer1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(4, 300, 19, stride=1, padding=0).cuda()\n",
    "        self.bn1 = nn.BatchNorm1d(300).cuda()\n",
    "        self.maxpool1 = nn.MaxPool1d(3).cuda()\n",
    "    \n",
    "    def forward(self, s):\n",
    "        return self.maxpool1(F.relu(self.bn1(self.conv1(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = layer1().cuda()\n",
    "l1_w_padding = deepcopy(l1)\n",
    "l1_w_padding.conv1.padding = (9,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer1(\n",
       "  (conv1): Conv1d(4, 300, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.eval()\n",
    "l1_w_padding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 300, 7])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(l1(torch.gather(padded_inp_seq, 2, inp_seq_slices)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        padded_inp_seq[:, :, 9:1009] = inp_seq_perturbed\n",
    "        l1(torch.gather(padded_inp_seq, 2, inp_seq_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 ms ± 1.16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 300, 7])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp1_out = l1(torch.gather(padded_inp_seq, 2, inp_seq_slices))\n",
    "mxp1_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 4, 1000])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_perturbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 300, 333])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp1_ism_out = l1_w_padding(inp_seq_perturbed)\n",
    "mxp1_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 170)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_ranges[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if equality holds for all slices\n",
    "all([torch.all(torch.isclose(mxp1_ism_out[i, :, range(*mxp1_out_ranges[i])], mxp1_out[i]))==True for i in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_and_scatter_mat(out_slices, out_offsets, outlen, num_channels):\n",
    "    inp_seq_slices = sum([list(range(*x)) for x in out_slices], [])\n",
    "    inp_seq_slices = torch.tensor(inp_seq_slices)\n",
    "    inp_seq_slices = inp_seq_slices.unsqueeze(0).repeat(num_channels,1).cuda()\n",
    "    \n",
    "    inp_scatter_mat = torch.tensor([list(range(x,x+outlen)) for x in out_offsets]).cuda()\n",
    "    inp_scatter_mat = inp_scatter_mat.unsqueeze(1).repeat(1,num_channels,1)\n",
    "    \n",
    "    return inp_seq_slices, inp_scatter_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mxp1_out_ref = l1_w_padding(inp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 333])\n",
      "torch.Size([300, 333])\n"
     ]
    }
   ],
   "source": [
    "print(mxp1_out_ref.shape)\n",
    "mxp1_out_ref = mxp1_out_ref.squeeze(0)\n",
    "print(mxp1_out_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mxp1_out_slices, mxp1_out_offsets), mxp2_out_ranges = get_idxs_conv_maxpool(333, 11, 5, 4, mxp1_out_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp_width = mxp1_out_slices[0][1]-mxp1_out_slices[0][0]\n",
    "print(conv2_inp_width)\n",
    "all([y-x==conv2_inp_width for x,y in mxp1_out_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp_num_channels = mxp1_out.shape[1]\n",
    "conv2_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 12,\n",
       "         6: 3,\n",
       "         7: 3,\n",
       "         8: 3,\n",
       "         9: 3,\n",
       "         10: 237,\n",
       "         11: 237,\n",
       "         12: 237,\n",
       "         13: 237,\n",
       "         14: 3,\n",
       "         15: 3,\n",
       "         16: 3,\n",
       "         17: 3,\n",
       "         18: 3,\n",
       "         19: 13})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mxp1_out_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_inp_seq_slices, conv2_inp_scatter_mat = get_slices_and_scatter_mat(mxp1_out_slices, mxp1_out_offsets, mxp1_out.shape[2], conv2_inp_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_conv2_inp_seq = torch.zeros(conv2_inp_num_channels, 343).cuda()\n",
    "padded_conv2_inp_seq[ :, 5:-5] = mxp1_out_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    padded_conv2_inp_seq[ :, 5:-5] = mxp1_out_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 µs ± 311 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 343])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_conv2_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 µs ± 55.8 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.gather(padded_conv2_inp_seq, 1, conv2_inp_seq_slices).view(conv2_inp_num_channels, 1000, conv2_inp_width).permute(1,0,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 µs ± 10.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit aligned.scatter_(2, conv2_inp_scatter_mat, mxp1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.gather(padded_conv2_inp_seq, 1, conv2_inp_seq_slices).view(conv2_inp_num_channels, 1000, conv2_inp_width).permute(1,0,2)\n",
    "aligned = aligned.scatter_(2, conv2_inp_scatter_mat, mxp1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 300, 30])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2 + Maxpool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(layer2, self).__init__()\n",
    "        self.conv = nn.Conv1d(300, 200, 11, stride=1, padding=0).cuda()\n",
    "        self.bn = nn.BatchNorm1d(200).cuda()\n",
    "        self.maxpool = nn.MaxPool1d(4).cuda()\n",
    "    \n",
    "    def forward(self, s):\n",
    "        return self.maxpool(F.relu(self.bn(self.conv(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = layer2().cuda()\n",
    "l2_w_padding = deepcopy(l2)\n",
    "l2_w_padding.conv.padding = (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer2(\n",
       "  (conv): Conv1d(300, 200, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.eval()\n",
    "l2_w_padding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 200, 5])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(l2(aligned).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        padded_conv2_inp_seq[ :, 5:-5] = mxp1_out_ref\n",
    "        aligned = torch.gather(padded_conv2_inp_seq, 1, conv2_inp_seq_slices).view(300, 1000, 30).permute(1,0,2)\n",
    "        aligned = aligned.scatter_(2, conv2_inp_scatter_mat, mxp1_out)\n",
    "        l2(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.62 ms ± 5.51 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 200, 5])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp2_out = l2(aligned)\n",
    "print(mxp2_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200, 83])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp2_ism_out = l2_w_padding(l1_w_padding(inp_seq_perturbed))\n",
    "mxp2_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 44)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_ranges[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# does not seem to hold for smaller atol values\n",
    "print(all([torch.all(torch.isclose(mxp2_ism_out[i, :, range(*mxp2_out_ranges[i])], mxp2_out[i], atol=1e-6))==True for i in range(1000)]))\n",
    "print(all([torch.all(torch.isclose(mxp2_out[i], mxp2_ism_out[i, :, range(*mxp2_out_ranges[i])], atol=1e-6))==True for i in range(1000)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mxp2_out_ref = l2_w_padding(l1_w_padding(inp_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 83])\n",
      "torch.Size([200, 83])\n"
     ]
    }
   ],
   "source": [
    "print(mxp2_out_ref.shape)\n",
    "mxp2_out_ref = mxp2_out_ref.squeeze(0)\n",
    "print(mxp2_out_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mxp2_out_slices, mxp2_out_offsets), mxp3_out_ranges = get_idxs_conv_maxpool(83, 7, 4, 4, mxp2_out_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp_width = mxp2_out_slices[0][1]-mxp2_out_slices[0][0]\n",
    "print(conv3_inp_width)\n",
    "all([y-x==conv3_inp_width for x,y in mxp2_out_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp_num_channels = mxp2_out.shape[1]\n",
    "conv3_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 36,\n",
       "         5: 12,\n",
       "         6: 216,\n",
       "         7: 216,\n",
       "         8: 216,\n",
       "         9: 216,\n",
       "         10: 12,\n",
       "         11: 12,\n",
       "         12: 12,\n",
       "         13: 12,\n",
       "         14: 40})"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mxp2_out_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_inp_seq_slices, conv3_inp_scatter_mat = get_slices_and_scatter_mat(mxp2_out_slices, mxp2_out_offsets, mxp2_out.shape[2], conv3_inp_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_conv3_inp_seq = torch.zeros(conv3_inp_num_channels, 91).cuda()\n",
    "padded_conv3_inp_seq[ :, 4:-4] = mxp2_out_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 91])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_conv3_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 µs ± 22.8 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.gather(padded_conv3_inp_seq, 1, conv3_inp_seq_slices).view(conv3_inp_num_channels, 1000, conv3_inp_width).permute(1,0,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 µs ± 18.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit aligned.scatter_(2, conv3_inp_scatter_mat, mxp2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.gather(padded_conv3_inp_seq, 1, conv3_inp_seq_slices).view(conv3_inp_num_channels, 1000, conv3_inp_width).permute(1,0,2)\n",
    "aligned = aligned.scatter_(2, conv3_inp_scatter_mat, mxp2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200, 22])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3 + Maxpool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(layer3, self).__init__()\n",
    "        self.conv = nn.Conv1d(200, 200, 7, stride=1, padding=0).cuda()\n",
    "        self.bn = nn.BatchNorm1d(200).cuda()\n",
    "        self.maxpool = nn.MaxPool1d(4).cuda()\n",
    "    \n",
    "    def forward(self, s):\n",
    "        return self.maxpool(F.relu(self.bn(self.conv(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = layer3().cuda()\n",
    "l3_w_padding = deepcopy(l3)\n",
    "l3_w_padding.conv.padding = (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "layer3(\n",
       "  (conv): Conv1d(200, 200, kernel_size=(7,), stride=(1,), padding=(4,))\n",
       "  (bn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3.eval()\n",
    "l3_w_padding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 200, 4])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(l3(aligned).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        padded_conv3_inp_seq[ :, 4:-4] = mxp2_out_ref\n",
    "        aligned = torch.gather(padded_conv3_inp_seq, 1, conv3_inp_seq_slices).view(conv3_inp_num_channels, 1000, conv3_inp_width).permute(1,0,2)\n",
    "        aligned = aligned.scatter_(2, conv3_inp_scatter_mat, mxp2_out)\n",
    "        l3(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 ms ± 2.79 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 200, 4])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp3_out = l3(aligned)\n",
    "print(mxp3_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = l2_w_padding(l1_w_padding(inp_seq_perturbed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        l3_w_padding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.88 ms ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200, 21])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mxp3_ism_out = l3_w_padding(l2_w_padding(l1_w_padding(inp_seq_perturbed)))\n",
    "mxp3_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 13)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_ranges[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# does not seem to hold for smaller atol values\n",
    "print(all([torch.all(torch.isclose(mxp3_ism_out[i, :, range(*mxp3_out_ranges[i])], mxp3_out[i], atol=1e-6))==True for i in range(1000)]))\n",
    "print(all([torch.all(torch.isclose(mxp3_out[i], mxp3_ism_out[i, :, range(*mxp3_out_ranges[i])], atol=1e-6))==True for i in range(1000)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mxp3_out_ref = l3_w_padding(l2_w_padding(l1_w_padding(inp_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 21])\n",
      "torch.Size([200, 21])\n"
     ]
    }
   ],
   "source": [
    "print(mxp3_out_ref.shape)\n",
    "mxp3_out_ref = mxp3_out_ref.squeeze(0)\n",
    "print(mxp3_out_ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next layer is FC layer, can be treated as conv with filter=width, no padding, no maxpool (maxpool width 1)\n",
    "(mxp3_out_slices, mxp3_out_offsets), _ = get_idxs_conv_maxpool(21, 21, 0, 1, mxp3_out_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp_width = mxp3_out_slices[0][1]-mxp3_out_slices[0][0]\n",
    "print(conv4_inp_width)\n",
    "all([y-x==conv4_inp_width for x,y in mxp3_out_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp_num_channels = mxp3_out.shape[1]\n",
    "conv4_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 96,\n",
       "         1: 48,\n",
       "         2: 48,\n",
       "         3: 48,\n",
       "         4: 48,\n",
       "         5: 48,\n",
       "         6: 48,\n",
       "         7: 48,\n",
       "         8: 48,\n",
       "         9: 48,\n",
       "         10: 48,\n",
       "         11: 48,\n",
       "         12: 48,\n",
       "         13: 48,\n",
       "         14: 48,\n",
       "         15: 48,\n",
       "         16: 48,\n",
       "         17: 136})"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mxp3_out_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need to slice, taking the entire mxp3_out_ref\n",
    "_, conv4_inp_scatter_mat = get_slices_and_scatter_mat(mxp3_out_slices, mxp3_out_offsets, mxp3_out.shape[2], conv4_inp_num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = mxp3_out_ref.clone().unsqueeze(0).repeat(1000,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200, 21])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.1 µs ± 16.6 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mxp3_out_ref.clone().unsqueeze(0).repeat(1000,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = aligned.scatter_(2, conv4_inp_scatter_mat, mxp3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 µs ± 4.78 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit aligned.scatter_(2, conv4_inp_scatter_mat, mxp3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200, 21])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with ref conv3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given the out_ranges, do the remaining values remain the same as output on original sequence?\n",
    "# this mostly debugs out_ranges\n",
    "truths = []\n",
    "for i in range(1000):\n",
    "    idxs = list(set(range(21)) - set(range(*mxp3_out_ranges[i])))\n",
    "    truths.append(bool(torch.all(torch.isclose(mxp3_out_ref[:,idxs], mxp3_ism_out[i][:,idxs], atol=1e-6))))\n",
    "sum(truths)\n",
    "\n",
    "# atol < 1e-6 doesn't work even when comparing what should be identical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is recreated pre fc output same as reference?\n",
    "torch.all(torch.isclose(aligned, mxp3_ism_out, atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCs (Fully Connected Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fc_layer, self).__init__()\n",
    "        self.fc1 = nn.Linear(4200, 1000)\n",
    "        self.bn4 = nn.BatchNorm1d(1000)\n",
    "\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.bn5 = nn.BatchNorm1d(1000)\n",
    "\n",
    "        self.fc3 = nn.Linear(1000, 10)\n",
    "    \n",
    "    def forward(self, s):\n",
    "        s = s.view(-1, 4200)\n",
    "        s = F.relu(self.bn4(self.fc1(s)))\n",
    "        s = F.relu(self.bn5(self.fc2(s)))\n",
    "        s = self.fc3(s)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fc_layer(\n",
       "  (fc1): Linear(in_features=4200, out_features=1000, bias=True)\n",
       "  (bn4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (bn5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcl = fc_layer().cuda()\n",
    "fcl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.isclose(fcl(l3_w_padding(l2_w_padding(l1_w_padding(inp_seq_perturbed)))),\n",
    "                        fcl(aligned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        aligned = mxp3_out_ref.clone().unsqueeze(0).repeat(1000,1,1)\n",
    "        aligned = aligned.scatter_(2, conv4_inp_scatter_mat, mxp3_out)\n",
    "        fcl(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.01 ms ± 4.31 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    with torch.no_grad():\n",
    "        fcl(aligned) # only fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.84 ms ± 4.77 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without optimisations\n",
    "def normalISM():\n",
    "    with torch.no_grad():\n",
    "        return fcl(l3_w_padding(l2_w_padding(l1_w_padding(inp_seq_perturbed))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalISM().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.3 ms ± 358 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastISM():\n",
    "    with torch.no_grad():\n",
    "        # first conv\n",
    "        padded_inp_seq[:, :, 9:1009] = inp_seq_perturbed\n",
    "        x = l1(torch.gather(padded_inp_seq, 2, inp_seq_slices))\n",
    "\n",
    "        # second conv\n",
    "        padded_conv2_inp_seq[ :, 5:-5] = mxp1_out_ref\n",
    "        aligned = torch.gather(padded_conv2_inp_seq, 1, conv2_inp_seq_slices).view(300, 1000, 30).permute(1,0,2)\n",
    "        aligned = aligned.scatter_(2, conv2_inp_scatter_mat, x)\n",
    "        x = l2(aligned)\n",
    "\n",
    "        # third conv\n",
    "        padded_conv3_inp_seq[ :, 4:-4] = mxp2_out_ref\n",
    "        aligned = torch.gather(padded_conv3_inp_seq, 1, conv3_inp_seq_slices).view(conv3_inp_num_channels, 1000, conv3_inp_width).permute(1,0,2)\n",
    "        aligned = aligned.scatter_(2, conv3_inp_scatter_mat, x)\n",
    "        x = l3(aligned)\n",
    "\n",
    "        # fc\n",
    "        aligned = mxp3_out_ref.clone().unsqueeze(0).repeat(1000,1,1)\n",
    "        aligned = aligned.scatter_(2, conv4_inp_scatter_mat, x)\n",
    "        x = fcl(aligned)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastISM().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.52 ms ± 11 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fastISM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.isclose(normalISM(), fastISM()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ms ± 844 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.rand(1000,4,1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
