{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSHAP Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import fastISM\n",
    "from fastISM.models.basset import basset_model\n",
    "\n",
    "from fastISM.models.factorized_basset import factorized_basset_model\n",
    "from fastISM.models.bpnet import bpnet_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import time\n",
    "\n",
    "import  shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fastISM' from '../fastISM/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(fastISM.flatten_model)\n",
    "reload(fastISM.models)\n",
    "reload(fastISM.ism_base)\n",
    "reload(fastISM.change_range)\n",
    "reload(fastISM.fast_ism_utils)\n",
    "reload(fastISM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/device:CPU:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kundajelab/tfmodisco_tf_models/blob/bd449328b/src/extract/dinuc_shuffle.py\n",
    "\n",
    "def string_to_char_array(seq):\n",
    "    \"\"\"\n",
    "    Converts an ASCII string to a NumPy array of byte-long ASCII codes.\n",
    "    e.g. \"ACGT\" becomes [65, 67, 71, 84].\n",
    "    \"\"\"\n",
    "    return np.frombuffer(bytes(seq, \"utf8\"), dtype=np.int8)\n",
    "\n",
    "\n",
    "def char_array_to_string(arr):\n",
    "    \"\"\"\n",
    "    Converts a NumPy array of byte-long ASCII codes into an ASCII string.\n",
    "    e.g. [65, 67, 71, 84] becomes \"ACGT\".\n",
    "    \"\"\"\n",
    "    return arr.tostring().decode(\"ascii\")\n",
    "\n",
    "\n",
    "def one_hot_to_tokens(one_hot):\n",
    "    \"\"\"\n",
    "    Converts an L x D one-hot encoding into an L-vector of integers in the range\n",
    "    [0, D], where the token D is used when the one-hot encoding is all 0. This\n",
    "    assumes that the one-hot encoding is well-formed, with at most one 1 in each\n",
    "    column (and 0s elsewhere).\n",
    "    \"\"\"\n",
    "    tokens = np.tile(one_hot.shape[1], one_hot.shape[0])  # Vector of all D\n",
    "    seq_inds, dim_inds = np.where(one_hot)\n",
    "    tokens[seq_inds] = dim_inds\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tokens_to_one_hot(tokens, one_hot_dim):\n",
    "    \"\"\"\n",
    "    Converts an L-vector of integers in the range [0, D] to an L x D one-hot\n",
    "    encoding. The value `D` must be provided as `one_hot_dim`. A token of D\n",
    "    means the one-hot encoding is all 0s.\n",
    "    \"\"\"\n",
    "    identity = np.identity(one_hot_dim + 1)[:, :-1]  # Last row is all 0s\n",
    "    return identity[tokens]\n",
    "\n",
    "\n",
    "def dinuc_shuffle(seq, num_shufs, rng=None):\n",
    "    \"\"\"\n",
    "    Creates shuffles of the given sequence, in which dinucleotide frequencies\n",
    "    are preserved.\n",
    "    Arguments:\n",
    "        `seq`: either a string of length L, or an L x D NumPy array of one-hot\n",
    "            encodings\n",
    "        `num_shufs`: the number of shuffles to create, N\n",
    "        `rng`: a NumPy RandomState object, to use for performing shuffles\n",
    "    If `seq` is a string, returns a list of N strings of length L, each one\n",
    "    being a shuffled version of `seq`. If `seq` is a 2D NumPy array, then the\n",
    "    result is an N x L x D NumPy array of shuffled versions of `seq`, also\n",
    "    one-hot encoded.\n",
    "    \"\"\"\n",
    "    if type(seq) is str:\n",
    "        arr = string_to_char_array(seq)\n",
    "    elif type(seq) is np.ndarray and len(seq.shape) == 2:\n",
    "        seq_len, one_hot_dim = seq.shape\n",
    "        arr = one_hot_to_tokens(seq)\n",
    "    else:\n",
    "        raise ValueError(\"Expected string or one-hot encoded array\")\n",
    "\n",
    "    if not rng:\n",
    "        rng = np.random.RandomState()\n",
    "   \n",
    "    # Get the set of all characters, and a mapping of which positions have which\n",
    "    # characters; use `tokens`, which are integer representations of the\n",
    "    # original characters\n",
    "    chars, tokens = np.unique(arr, return_inverse=True)\n",
    "\n",
    "    # For each token, get a list of indices of all the tokens that come after it\n",
    "    shuf_next_inds = []\n",
    "    for t in range(len(chars)):\n",
    "        mask = tokens[:-1] == t  # Excluding last char\n",
    "        inds = np.where(mask)[0]\n",
    "        shuf_next_inds.append(inds + 1)  # Add 1 for next token\n",
    " \n",
    "    if type(seq) is str:\n",
    "        all_results = []\n",
    "    else:\n",
    "        all_results = np.empty(\n",
    "            (num_shufs, seq_len, one_hot_dim), dtype=seq.dtype\n",
    "        )\n",
    "\n",
    "    for i in range(num_shufs):\n",
    "        # Shuffle the next indices\n",
    "        for t in range(len(chars)):\n",
    "            inds = np.arange(len(shuf_next_inds[t]))\n",
    "            inds[:-1] = rng.permutation(len(inds) - 1)  # Keep last index same\n",
    "            shuf_next_inds[t] = shuf_next_inds[t][inds]\n",
    "\n",
    "        counters = [0] * len(chars)\n",
    "       \n",
    "        # Build the resulting array\n",
    "        ind = 0\n",
    "        result = np.empty_like(tokens)\n",
    "        result[0] = tokens[ind]\n",
    "        for j in range(1, len(tokens)):\n",
    "            t = tokens[ind]\n",
    "            ind = shuf_next_inds[t][counters[t]]\n",
    "            counters[t] += 1\n",
    "            result[j] = tokens[ind]\n",
    "\n",
    "        if type(seq) is str:\n",
    "            all_results.append(char_array_to_string(chars[result]))\n",
    "        else:\n",
    "            all_results[i] = tokens_to_one_hot(chars[result], one_hot_dim)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/kundajelab/tfmodisco_tf_models/blob/bd449328b22/src/extract/compute_profile_shap.py\n",
    "\n",
    "def create_background(model_inputs, bg_size=10, seed=20191206):\n",
    "    \"\"\"\n",
    "    From a pair of single inputs to the model, generates the set of background\n",
    "    inputs to perform interpretation against.\n",
    "    Arguments:\n",
    "        `model_inputs`: a pair of two entries; the first is a single one-hot\n",
    "            encoded input sequence of shape I x 4; the second is the set of\n",
    "            control profiles for the model, shaped T x O x 2\n",
    "        `bg_size`: the number of background examples to generate.\n",
    "    Returns a pair of arrays as a list, where the first array is G x I x 4, and\n",
    "    the second array is G x T x O x 2; these are the background inputs. The\n",
    "    background for the input sequences is randomly dinuceotide-shuffles of the\n",
    "    original sequence. The background for the control profiles is the same as\n",
    "    the originals.\n",
    "    \"\"\"\n",
    "    input_seq = model_inputs[0]\n",
    "    rng = np.random.RandomState(seed)\n",
    "    input_seq_bg = dinuc_shuffle(input_seq, bg_size, rng=rng)\n",
    "    return input_seq_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.36.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.explainers._deep.deep_tf.op_handlers[\"AddV2\"] = shap.explainers._deep.deep_tf.passthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset/Factorized Basset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [1,32,64,128,256,512, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "MODEL: <function basset_model at 0x7fc152795b90>\n",
      "SEQLEN: 1000\n",
      "BATCH SIZE: 1\tTIME: 0.03\tPER 100: 2.56\n",
      "BATCH SIZE: 32\tTIME: 0.67\tPER 100: 2.09\n",
      "BATCH SIZE: 64\tTIME: 1.19\tPER 100: 1.86\n",
      "BATCH SIZE: 128\tTIME: 2.24\tPER 100: 1.75\n",
      "BATCH SIZE: 256\tTIME: 4.48\tPER 100: 1.75\n",
      "BATCH SIZE: 512\tTIME: 8.95\tPER 100: 1.75\n",
      "BATCH SIZE: 1024\tTIME: 17.97\tPER 100: 1.75\n",
      "BEST PER 100: 1.75\n",
      "\n",
      "------------------\n",
      "MODEL: <function basset_model at 0x7fc152795b90>\n",
      "SEQLEN: 2000\n",
      "BATCH SIZE: 1\tTIME: 0.03\tPER 100: 3.14\n",
      "BATCH SIZE: 32\tTIME: 0.97\tPER 100: 3.04\n",
      "BATCH SIZE: 64\tTIME: 1.95\tPER 100: 3.05\n",
      "BATCH SIZE: 128\tTIME: 3.89\tPER 100: 3.04\n",
      "BATCH SIZE: 256\tTIME: 7.79\tPER 100: 3.04\n",
      "BATCH SIZE: 512\tTIME: 15.61\tPER 100: 3.05\n",
      "BATCH SIZE: 1024\tTIME: 31.29\tPER 100: 3.06\n",
      "BEST PER 100: 3.04\n",
      "\n",
      "------------------\n",
      "MODEL: <function factorized_basset_model at 0x7fc152795c20>\n",
      "SEQLEN: 1000\n",
      "BATCH SIZE: 1\tTIME: 0.03\tPER 100: 2.69\n",
      "BATCH SIZE: 32\tTIME: 0.85\tPER 100: 2.64\n",
      "BATCH SIZE: 64\tTIME: 1.69\tPER 100: 2.64\n",
      "BATCH SIZE: 128\tTIME: 3.38\tPER 100: 2.64\n",
      "BATCH SIZE: 256\tTIME: 6.77\tPER 100: 2.64\n",
      "BATCH SIZE: 512\tTIME: 13.81\tPER 100: 2.70\n",
      "BATCH SIZE: 1024\tTIME: 27.64\tPER 100: 2.70\n",
      "BEST PER 100: 2.64\n",
      "\n",
      "------------------\n",
      "MODEL: <function factorized_basset_model at 0x7fc152795c20>\n",
      "SEQLEN: 2000\n",
      "BATCH SIZE: 1\tTIME: 0.05\tPER 100: 4.76\n",
      "BATCH SIZE: 32\tTIME: 1.50\tPER 100: 4.68\n",
      "BATCH SIZE: 64\tTIME: 2.97\tPER 100: 4.63\n",
      "BATCH SIZE: 128\tTIME: 5.97\tPER 100: 4.66\n",
      "BATCH SIZE: 256\tTIME: 11.98\tPER 100: 4.68\n",
      "BATCH SIZE: 512\tTIME: 23.94\tPER 100: 4.68\n",
      "BATCH SIZE: 1024\tTIME: 47.92\tPER 100: 4.68\n",
      "BEST PER 100: 4.63\n"
     ]
    }
   ],
   "source": [
    "# shap_values most likely internally creates a batch for each example\n",
    "# thus time per 100 examples stays near constant with batch size\n",
    "\n",
    "for model_type in [basset_model, factorized_basset_model]:\n",
    "    for seqlen in [1000, 2000]:\n",
    "        print(\"\\n------------------\")\n",
    "        print(\"MODEL: {}\".format(model_type))\n",
    "        print(\"SEQLEN: {}\".format(seqlen))\n",
    "        model = model_type(seqlen=seqlen, num_outputs=1)\n",
    "        \n",
    "        # dry run \n",
    "        e = shap.DeepExplainer(model, data=create_background)\n",
    "        o = e.shap_values(np.random.random((10,seqlen,4)), check_additivity=False)\n",
    "        \n",
    "        times = []\n",
    "        per_100 = []\n",
    "        for b in BATCH_SIZES:\n",
    "            x = np.random.random((b,seqlen,4))\n",
    "            t = time.time()\n",
    "            e.shap_values(x, check_additivity=False)\n",
    "            times.append(time.time()-t)\n",
    "            per_100.append((times[-1]/b)*100)\n",
    "            print(\"BATCH SIZE: {}\\tTIME: {:.2f}\\tPER 100: {:.2f}\".format(b, times[-1], (times[-1]/b)*100))\n",
    "        \n",
    "        print(\"BEST PER 100: {:.2f}\".format(min(per_100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [1,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear ops\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"BatchToSpaceND\"] = shap.explainers._deep.deep_tf.passthrough\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"SpaceToBatchND\"] = shap.explainers._deep.deep_tf.passthrough\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"Conv2DBackpropInput\"] = shap.explainers._deep.deep_tf.passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow throws warnings that stem from creating lots of explainers\n",
    "# suppress them\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "SEQLEN: 1000\n",
      "BATCH SIZE: 1\tTIME: 17.80\tPER 100: 1779.57\n",
      "BATCH SIZE: 8\tTIME: 139.47\tPER 100: 1743.35\n",
      "BEST PER 100: 1743.35\n",
      "\n",
      "------------------\n",
      "SEQLEN: 2000\n",
      "BATCH SIZE: 1\tTIME: 65.06\tPER 100: 6506.26\n",
      "BATCH SIZE: 8\tTIME: 514.22\tPER 100: 6427.77\n",
      "BEST PER 100: 6427.77\n"
     ]
    }
   ],
   "source": [
    "for seqlen in [1000, 2000]:\n",
    "    print(\"\\n------------------\")\n",
    "    print(\"SEQLEN: {}\".format(seqlen))\n",
    "    model = bpnet_model(seqlen=seqlen, num_dilated_convs=9)\n",
    "\n",
    "    # run explainers for each position\n",
    "    times = [0 for _ in BATCH_SIZES]\n",
    "    for i in range(seqlen):\n",
    "        e = shap.DeepExplainer((model.input, model.output[0][:,i]), data=create_background)\n",
    "        # dry run\n",
    "        o = e.shap_values(np.random.random((1,seqlen,4)), check_additivity=False)\n",
    "        \n",
    "        # batch sizes in inner loop to make explainers only once for diff batch sizes\n",
    "        # making explainers is the bottleneck\n",
    "        for b_idx, b in enumerate(BATCH_SIZES):\n",
    "            x = np.random.random((b,seqlen,4))\n",
    "\n",
    "            # time taken for this position (excluding time taken for setting up explainers)            \n",
    "            t = time.time()\n",
    "            e.shap_values(x, check_additivity=False)\n",
    "            times[b_idx] += time.time()-t\n",
    "\n",
    "    # counts output\n",
    "    e = shap.DeepExplainer((model.input, model.output[1]), data=create_background)\n",
    "    # dry run\n",
    "    o = e.shap_values(np.random.random((1,seqlen,4)), check_additivity=False)\n",
    "\n",
    "    for b_idx, b in enumerate(BATCH_SIZES):\n",
    "        x = np.random.random((b,seqlen,4))\n",
    "\n",
    "        # time taken for this position (excluding time taken for setting up explainers)            \n",
    "        t = time.time()\n",
    "        e.shap_values(x, check_additivity=False)\n",
    "        times[b_idx] += time.time()-t\n",
    "\n",
    "    per_100 = [(x/BATCH_SIZES[i])*100 for i,x in enumerate(times)]\n",
    "    \n",
    "    for i,x in enumerate(times):        \n",
    "        print(\"BATCH SIZE: {}\\tTIME: {:.2f}\\tPER 100: {:.2f}\".format(BATCH_SIZES[i], x, per_100[i]))\n",
    "\n",
    "    print(\"BEST PER 100: {:.2f}\".format(min(per_100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
