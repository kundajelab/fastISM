{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise ISM for the Basset Architecture\n",
    "\n",
    "Proof of concept in tf/Keras, essentially a copy of the PyTorch notebook. \n",
    "\n",
    "One key difference is this noteobok would forward prop with multiple examples, each having mutation in the same ith regions. This is different compared to the PyTorch notebook, in which each forward prop has the same sequence with mutations at different positions, which made the bookkeeping harder. Inspired by discussions with Av.\n",
    "\n",
    "Architecture (PyTorch): [link](https://github.com/kundajelab/GenoPyT/blob/c84f38dfaa0c986f91383dd7e6278c1cb993498d/src/models/sequence_only/basset.py). Padding changed for last layer since Keras allows 'same' or 'valid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs_conv_maxpool(seqlen, kernelsize, padding, maxpool_kernel, change_ranges, \n",
    "                          conv_stride=1,\n",
    "                          maxpool_stride=None,\n",
    "                          maxpool_ceil_mode=False): \n",
    "\n",
    "    # assumes stride==1 for conv and stride=kernel for maxpool \n",
    "    # change ranges are BEFORE padding \n",
    "    # indexes returned are slices AFTER padding input seqs\n",
    "    \n",
    "    if maxpool_ceil_mode==True or conv_stride!=1 or maxpool_stride!=None: \n",
    "        # will take extra care, e.g. repeat values in last block  \n",
    "        raise NotImplementedError \n",
    "     \n",
    "    # raw ranges for each change_range -- this is the input range in which\n",
    "    # changing the change_range will affect the output\n",
    "    raw_seq_ranges = [(x-kernelsize+1,y+kernelsize-1) for x,y in change_ranges] \n",
    "     \n",
    "    # re-adjust since there will be `padding` number of zeros in the beginning \n",
    "    raw_seq_pad_adjusted = [(x+padding, y+padding) for x,y in raw_seq_ranges] \n",
    "     \n",
    "    range_corrected = [] \n",
    "    for x,y in raw_seq_pad_adjusted: \n",
    "        # shift around the edges\n",
    "        if x<0 and y>seqlen+2*padding: # kinda degenerate, required when using for fc layers\n",
    "            range_corrected.append((0,seqlen+2*padding))\n",
    "        elif x<0: \n",
    "            range_corrected.append((0, y-x)) \n",
    "        elif y > seqlen+2*padding: \n",
    "            range_corrected.append((x-(y-seqlen-2*padding),seqlen+2*padding)) \n",
    "        else: \n",
    "            range_corrected.append((x,y)) \n",
    "\n",
    "    # the conv output range affected by each input\n",
    "    conv_out_ranges = [(x,y-kernelsize+1) for x,y in range_corrected] \n",
    "\n",
    "    # length of sequence after convolution\n",
    "    conv_seqlen = seqlen + 2*padding - kernelsize + 1\n",
    "    \n",
    "    # shift to the edges of the nearest maxpool block\n",
    "    mod_shifted = [(maxpool_kernel*(x//maxpool_kernel), \n",
    "                   maxpool_kernel*((y-1)//maxpool_kernel+1)) for x,y in conv_out_ranges] \n",
    "    # each should be the same size\n",
    "    maxwidth = max([y-x for x,y in mod_shifted])  \n",
    "\n",
    "    mod_shifted = [(x,x+maxwidth) if y<=conv_seqlen else (y-maxwidth, y) for x,y in mod_shifted]  \n",
    "     \n",
    "    # when ceil_mode==False, this works by ignoring last block [ceil_mode==False also ignores last block]  \n",
    "    mod_shifted = [(x,y) if y<=conv_seqlen else (x-maxpool_kernel,y-maxpool_kernel) for x,y in mod_shifted]  \n",
    "    assert([y<=conv_seqlen for _,y in mod_shifted])  \n",
    "    \n",
    "    # this would be the output ranges AFTER maxpool\n",
    "    out_ranges = [(x//maxpool_kernel, y//maxpool_kernel) for x,y in mod_shifted]  \n",
    "     \n",
    "    # work back input slices for desired output maxpool ranges\n",
    "    slice_ranges = [(x,y+kernelsize-1) for x,y in mod_shifted] \n",
    "    \n",
    "    offsets = [x+padding-slice_ranges[i][0] for i,(x,_) in enumerate(change_ranges)] \n",
    "    \n",
    "    return (slice_ranges, offsets), out_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_POS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "([s_slice], _), [mxp1_out_range] = get_idxs_conv_maxpool(1000, 19, 9, 3, [(MUT_POS,MUT_POS+1)])\n",
    "inp_width = s_slice[1]-s_slice[0]\n",
    "print(inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input sequence \n",
    "inp_seq_np = np.random.randn(1000,1000,4)\n",
    "inp_seq_np = inp_seq_np.astype(np.float32)\n",
    "inp_seq_perturbed_np = np.copy(inp_seq_np)\n",
    "inp_seq_perturbed_np[:, MUT_POS, :] = 0\n",
    "\n",
    "inp_seq = tf.constant(inp_seq_np)\n",
    "inp_seq_perturbed = tf.constant(inp_seq_perturbed_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1018, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq = tf.concat([tf.zeros((1000,9,4)), \n",
    "                            inp_seq_perturbed, \n",
    "                            tf.zeros((1000,9,4))], \n",
    "                           axis=1)\n",
    "padded_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 129)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 µs ± 1.67 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit padded_inp_seq[:, s_slice[0]:s_slice[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1 + Maxpool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = tf.keras.Sequential()\n",
    "l1.add(tf.keras.layers.Conv1D(300, 19, strides=1, padding='valid'))\n",
    "l1.add(tf.keras.layers.BatchNormalization())\n",
    "l1.add(tf.keras.layers.MaxPool1D(3))\n",
    "\n",
    "l1_w_padding = tf.keras.models.clone_model(l1)\n",
    "l1_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l1.build(input_shape=(None,s_slice[1]-s_slice[0],4))\n",
    "l1_w_padding.build(input_shape=(None, 1000, 4))\n",
    "l1_w_padding.layers[0].set_weights(l1.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7, 300)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out = l1.predict(padded_inp_seq[:, s_slice[0]:s_slice[1], :])\n",
    "mxp1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1018, 4])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1000, 4])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_perturbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.6 ms ± 567 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l1.predict(padded_inp_seq[:, s_slice[0]:s_slice[1], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 333, 300)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_ism_out = l1_w_padding.predict(inp_seq_perturbed)\n",
    "mxp1_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915 ms ± 19.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l1_w_padding.predict(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 37)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(tf.equal(mxp1_out, mxp1_ism_out[:,range(*mxp1_out_range)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 333, 300)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_ref = l1_w_padding.predict(inp_seq)\n",
    "mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "([mxp1_out_slice], [mxp1_out_offset]), [mxp2_out_range] = get_idxs_conv_maxpool(333, 11, 5, 4, [mxp1_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "conv2_inp_width = mxp1_out_slice[1]-mxp1_out_slice[0]\n",
    "print(conv2_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp_num_channels = mxp1_out.shape[2]\n",
    "conv2_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 54)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 11)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 333, 300)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 343, 300])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp1_out_ref = tf.concat([tf.zeros((1000,5,mxp1_out_ref.shape[2])), \n",
    "                            mxp1_out_ref, \n",
    "                            tf.zeros((1000,5,mxp1_out_ref.shape[2]))], \n",
    "                           axis=1)\n",
    "padded_mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 30, 300])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp = tf.concat([padded_mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[0]+mxp1_out_offset],\n",
    "                      mxp1_out,\n",
    "                      padded_mxp1_out_ref[:, mxp1_out_slice[0]+mxp1_out_offset+mxp1_out.shape[1]:mxp1_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv2_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2 + Maxpool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = tf.keras.Sequential()\n",
    "l2.add(tf.keras.layers.Conv1D(200, 11, strides=1, padding='valid'))\n",
    "l2.add(tf.keras.layers.BatchNormalization())\n",
    "l2.add(tf.keras.layers.MaxPool1D(4))\n",
    "\n",
    "l2_w_padding = tf.keras.models.clone_model(l2)\n",
    "l2_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l2.build(input_shape=(None,mxp1_out_slice[1]-mxp1_out_slice[0],conv2_inp_num_channels))\n",
    "l2_w_padding.build(input_shape=(None, mxp1_ism_out.shape[1], conv2_inp_num_channels))\n",
    "l2_w_padding.layers[0].set_weights(l2.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 5, 200])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out = l2(conv2_inp)\n",
    "mxp2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    l2(tf.concat([mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[0]+mxp1_out_offset],\n",
    "                      mxp1_out,\n",
    "                      mxp1_out_ref[:, mxp1_out_slice[0]+mxp1_out_offset+mxp1_out.shape[1]:mxp1_out_slice[1]]],\n",
    "                     axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.1 ms ± 1.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 83, 200)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_ism_out = l2_w_padding.predict(mxp1_ism_out)\n",
    "mxp2_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 s ± 16.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l2_w_padding.predict(mxp1_ism_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(tf.equal(mxp2_out, mxp2_ism_out[:,range(*mxp2_out_range)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 83, 200)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_ref = l2_w_padding.predict(mxp1_out_ref)\n",
    "mxp2_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "([mxp2_out_slice], [mxp2_out_offset]), [mxp3_out_range] = get_idxs_conv_maxpool(83, 7, 3, 4, [mxp2_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "conv3_inp_width = mxp2_out_slice[1]-mxp2_out_slice[0]\n",
    "print(conv3_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp_num_channels = mxp2_out.shape[2]\n",
    "conv3_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 89, 200])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp2_out_ref = tf.concat([tf.zeros((1000,3,mxp2_out_ref.shape[2])), \n",
    "                            mxp2_out_ref, \n",
    "                            tf.zeros((1000,3,mxp2_out_ref.shape[2]))], \n",
    "                           axis=1)\n",
    "padded_mxp2_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 22, 200])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp = tf.concat([padded_mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[0]+mxp2_out_offset],\n",
    "                      mxp2_out,\n",
    "                      padded_mxp2_out_ref[:, mxp2_out_slice[0]+mxp2_out_offset+mxp2_out.shape[1]:mxp2_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv3_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3 + Maxpool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = tf.keras.Sequential()\n",
    "l3.add(tf.keras.layers.Conv1D(200, 7, strides=1, padding='valid'))\n",
    "l3.add(tf.keras.layers.BatchNormalization())\n",
    "l3.add(tf.keras.layers.MaxPool1D(4))\n",
    "\n",
    "l3_w_padding = tf.keras.models.clone_model(l3)\n",
    "l3_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l3.build(input_shape=(None,mxp2_out_slice[1]-mxp2_out_slice[0],conv3_inp_num_channels))\n",
    "l3_w_padding.build(input_shape=(None, mxp2_ism_out.shape[1], conv3_inp_num_channels))\n",
    "l3_w_padding.layers[0].set_weights(l3.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 4, 200])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out = l3(conv3_inp)\n",
    "mxp3_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    l3(tf.concat([mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[0]+mxp2_out_offset],\n",
    "                      mxp2_out,\n",
    "                      mxp2_out_ref[:, mxp2_out_slice[0]+mxp2_out_offset+mxp2_out.shape[1]:mxp2_out_slice[1]]],\n",
    "                     axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.6 ms ± 547 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20, 200)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_ism_out = l3_w_padding.predict(mxp2_ism_out)\n",
    "mxp3_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 ms ± 3.28 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l3_w_padding.predict(mxp2_ism_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(tf.equal(mxp3_out, mxp3_ism_out[:,range(*mxp3_out_range)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20, 200)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_ref = l3_w_padding.predict(mxp2_out_ref)\n",
    "mxp3_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next layer is FC layer, can be treated as conv with filter=width, no padding, no maxpool (maxpool width 1)\n",
    "([mxp3_out_slice], [mxp3_out_offset]), _ = get_idxs_conv_maxpool(20, 20, 0, 1, [mxp3_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "conv4_inp_width = mxp3_out_slice[1]-mxp3_out_slice[0]\n",
    "print(conv4_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp_num_channels = mxp3_out.shape[2]\n",
    "conv4_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 20, 200])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp = tf.concat([mxp3_out_ref[:, mxp3_out_slice[0]:mxp3_out_slice[0]+mxp3_out_offset],\n",
    "                      mxp3_out,\n",
    "                      mxp3_out_ref[:, mxp3_out_slice[0]+mxp3_out_offset+mxp3_out.shape[1]:mxp3_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv4_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with ISM conv3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(tf.equal(conv4_inp, mxp3_ism_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCs (Fully Connected Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs = tf.keras.Sequential()\n",
    "fcs.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "fcs.add(tf.keras.layers.BatchNormalization())\n",
    "fcs.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "fcs.add(tf.keras.layers.BatchNormalization())\n",
    "fcs.add(tf.keras.layers.Dense(10))\n",
    "fcs.build(input_shape=(None,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output -> reshape -> fc\n",
    "def f():\n",
    "    fcs.predict(tf.reshape(tf.concat([mxp3_out_ref[:, mxp3_out_slice[0]:mxp3_out_slice[0]+mxp3_out_offset],\n",
    "                      mxp3_out,\n",
    "                      mxp3_out_ref[:, mxp3_out_slice[0]+mxp3_out_offset+mxp3_out.shape[1]:mxp3_out_slice[1]]],\n",
    "                     axis=1),\n",
    "               (-1,4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 ms ± 2.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only reshape -> fc\n",
    "def f():\n",
    "    fcs.predict(tf.reshape(mxp3_ism_out, (-1,4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 ms ± 1.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without optimisations\n",
    "def normalISMModel():\n",
    "    inp = tf.keras.Input(shape=(1000,4))\n",
    "\n",
    "    # conv mxp 1\n",
    "    x = tf.keras.layers.Conv1D(300, 19, strides=1, padding='same', name='conv1')(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    # conv mxp 2\n",
    "    x = tf.keras.layers.Conv1D(200, 11, strides=1, padding='same', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # conv mxp 3\n",
    "    x = tf.keras.layers.Conv1D(200, 7, strides=1, padding='same', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # fc\n",
    "    x = tf.keras.layers.Reshape((4000,))(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(10, name='fc3')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inp, outputs=x, name='normalISM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ISM_model = normalISMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_normal():\n",
    "    return normal_ISM_model.predict_on_batch(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97 s ± 38.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceAssign(tf.keras.layers.Layer): \n",
    "    def __init__(self, b_dim): \n",
    "        super(SliceAssign, self).__init__() \n",
    "        \n",
    "        # after one slice assign, tf can't calculate dimension \n",
    "        # since i is not known. So manually specify b_dim\n",
    "        self.b_dim = b_dim\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # GOAL: a[:,i:i+b.shape[1]] = b\n",
    "\n",
    "        a, b, i = inputs\n",
    "        # output will lose shape info (dim 1 will be set to None)\n",
    "        return tf.concat([a[:,:i[0]], b, a[:,i[0]+self.b_dim:]], axis=1) \n",
    "    \n",
    "    \n",
    "def fastISMModel():\n",
    "    inp = tf.keras.Input(shape=(inp_width,4))\n",
    "    padded_mxp1_out_ref = tf.keras.Input(shape=(conv2_inp_width, conv2_inp_num_channels))\n",
    "    mxp1_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    padded_mxp2_out_ref = tf.keras.Input(shape=(conv3_inp_width, conv3_inp_num_channels))\n",
    "    mxp2_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    mxp3_out_ref = tf.keras.Input(shape=(conv4_inp_width, conv4_inp_num_channels))\n",
    "    mxp3_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    # conv mxp 1\n",
    "    x = tf.keras.layers.Conv1D(300, 19, strides=1, padding='valid', name='conv1')(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp1_out_range[1]-mxp1_out_range[0])([padded_mxp1_out_ref, x, mxp1_out_offset])\n",
    "\n",
    "    # conv mxp 2\n",
    "    x = tf.keras.layers.Conv1D(200, 11, strides=1, padding='valid', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp2_out_range[1]-mxp2_out_range[0])([padded_mxp2_out_ref, x, mxp2_out_offset])\n",
    "    \n",
    "    # conv mxp 3\n",
    "    x = tf.keras.layers.Conv1D(200, 7, strides=1, padding='valid', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp3_out_range[1]-mxp3_out_range[0])([mxp3_out_ref, x, mxp3_out_offset])\n",
    "    \n",
    "    # fc\n",
    "    x = tf.keras.layers.Reshape((4000,))(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(10, name='fc3')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inp, \n",
    "                                   padded_mxp1_out_ref, mxp1_out_offset,\n",
    "                                   padded_mxp2_out_ref, mxp2_out_offset,\n",
    "                                   mxp3_out_ref, mxp3_out_offset], \n",
    "                           outputs=x, name='fastISM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_ISM_model = fastISMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs \n",
    "type(padded_mxp1_out_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 39, 4])"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq[:, s_slice[0]:s_slice[1], :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 343, 300])"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fast():\n",
    "    return fast_ISM_model.predict_on_batch([padded_inp_seq[:, s_slice[0]:s_slice[1], :],\n",
    "                       padded_mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[1]], tf.ones(1)*mxp1_out_offset, \n",
    "                       padded_mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[1]], tf.ones(1)*mxp2_out_offset, \n",
    "                       mxp3_out_ref, tf.ones(1)*mxp3_out_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 ms ± 1.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run so they build weights if haven't\n",
    "run_normal()\n",
    "run_fast()\n",
    "\n",
    "# set weights to those from initial layers so that tensors like `padded_mxp1_out_ref` can be reused\n",
    "fast_ISM_model.get_layer(\"conv1\").set_weights(l1.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv1\").set_weights(l1.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"conv2\").set_weights(l2.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv2\").set_weights(l2.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"conv3\").set_weights(l3.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv3\").set_weights(l3.layers[0].get_weights())\n",
    "\n",
    "# fcs\n",
    "fast_ISM_model.get_layer(\"fc1\").set_weights(fcs.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc1\").set_weights(fcs.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"fc2\").set_weights(fcs.layers[2].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc2\").set_weights(fcs.layers[2].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"fc3\").set_weights(fcs.layers[4].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc3\").set_weights(fcs.layers[4].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(tf.equal(run_normal(), run_fast()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
