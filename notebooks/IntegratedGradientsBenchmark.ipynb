{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import fastISM\n",
    "from fastISM.models.basset import basset_model\n",
    "\n",
    "from fastISM.models.factorized_basset import factorized_basset_model\n",
    "from fastISM.models.bpnet import bpnet_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fastISM' from '../fastISM/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(fastISM.flatten_model)\n",
    "reload(fastISM.models)\n",
    "reload(fastISM.ism_base)\n",
    "reload(fastISM.change_range)\n",
    "reload(fastISM.fast_ism_utils)\n",
    "reload(fastISM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep  8 09:53:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    27W / 250W |      0MiB / 16280MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-0d9a859c-ce19-78f3-2f87-aade11d14bae)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Wed_Apr_24_19:10:27_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.168\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/device:CPU:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "from alibi.explainers import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alibi.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ig(model, batch_sizes, seqlen, num_examples=500, n_steps=50, targets = [None]):\n",
    "    x = np.random.random((num_examples,seqlen,4))\n",
    "    times = []\n",
    "    per_100 = []\n",
    "    for b in batch_sizes:\n",
    "        ig  = IntegratedGradients(model,\n",
    "                              layer=None,\n",
    "                              method=\"gausslegendre\",\n",
    "                              n_steps=n_steps,\n",
    "                              internal_batch_size=b)\n",
    "        # dry run\n",
    "        ig.explain(x[:10], baselines=None,\n",
    "                   target=targets[0])\n",
    "        \n",
    "        t = time.time()\n",
    "        for tgt in targets:\n",
    "            ig.explain(x, baselines=None,\n",
    "                       target=tgt)\n",
    "        times.append(time.time()-t)\n",
    "        per_100.append((times[-1]/num_examples)*100)\n",
    "        print(\"BATCH: {}\\tTIME: {:.2f}\\tPER 100: {:.2f}\".format(b, times[-1], (times[-1]/num_examples)*100))\n",
    "    \n",
    "    print(\"BEST PER 100: {:.2f}\".format(min(per_100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basset_model(seqlen=1000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.26\tPER 100: 2.62\n",
      "BATCH: 200\tTIME: 0.24\tPER 100: 2.37\n",
      "BATCH: 500\tTIME: 0.25\tPER 100: 2.50\n",
      "BEST PER 100: 2.37\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout \n",
    "# hide warning about scalar output\n",
    "\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=10, targets=[None]) # targets None since only one scalar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 2.77\tPER 100: 2.77\n",
      "BATCH: 200\tTIME: 2.39\tPER 100: 2.39\n",
      "BATCH: 500\tTIME: 2.34\tPER 100: 2.34\n",
      "BATCH: 1000\tTIME: 3.28\tPER 100: 3.28\n",
      "BEST PER 100: 2.34\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500, 1000], 1000, num_examples=100, targets=[None]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basset_model(seqlen=2000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.48\tPER 100: 4.80\n",
      "BATCH: 200\tTIME: 0.48\tPER 100: 4.76\n",
      "BATCH: 500\tTIME: 0.48\tPER 100: 4.82\n",
      "BEST PER 100: 4.76\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500], 2000, num_examples=10, targets=[None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 4.77\tPER 100: 4.77\n",
      "BATCH: 200\tTIME: 4.63\tPER 100: 4.63\n",
      "BATCH: 500\tTIME: 4.61\tPER 100: 4.61\n",
      "BEST PER 100: 4.61\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500], 2000, num_examples=100, targets=[None]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorized Basset (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = factorized_basset_model(seqlen=1000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.54\tPER 100: 5.40\n",
      "BATCH: 200\tTIME: 0.51\tPER 100: 5.14\n",
      "BATCH: 500\tTIME: 0.50\tPER 100: 5.00\n",
      "BEST PER 100: 5.00\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=10, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 5.18\tPER 100: 5.18\n",
      "BATCH: 200\tTIME: 4.92\tPER 100: 4.92\n",
      "BATCH: 500\tTIME: 4.82\tPER 100: 4.82\n",
      "BEST PER 100: 4.82\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=100, targets=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorized Basset (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = factorized_basset_model(seqlen=2000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.99\tPER 100: 9.89\n",
      "BATCH: 200\tTIME: 0.97\tPER 100: 9.73\n",
      "BATCH: 300\tTIME: 0.95\tPER 100: 9.47\n",
      "BEST PER 100: 9.47\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=10, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 9.90\tPER 100: 9.90\n",
      "BATCH: 200\tTIME: 9.56\tPER 100: 9.56\n",
      "BATCH: 300\tTIME: 9.53\tPER 100: 9.53\n",
      "BEST PER 100: 9.53\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=100, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 19.84\tPER 100: 9.92\n",
      "BATCH: 200\tTIME: 19.14\tPER 100: 9.57\n",
      "BATCH: 300\tTIME: 19.07\tPER 100: 9.54\n",
      "BEST PER 100: 9.54\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=200, targets=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPNet (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpnet_model(seqlen=1000, num_dilated_convs=9)\n",
    "\n",
    "# flatten and concat outputs\n",
    "inp = tf.keras.Input(shape=model.input_shape[1:])\n",
    "prof, cts = model(inp)\n",
    "prof = tf.keras.layers.Flatten()(prof)\n",
    "cts = tf.keras.layers.Flatten()(cts)\n",
    "out = tf.keras.layers.Concatenate()([prof, cts])\n",
    "model_ig = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "# flattened outputs\n",
    "model = model_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 1001) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 500\tTIME: 439.95\tPER 100: 4399.53\n",
      "BEST PER 100: 4399.53\n"
     ]
    }
   ],
   "source": [
    "time_ig(model, [500], 1000, num_examples=10, targets=range(1001)) # all 1000 profile outs + 1 count out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPNet (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpnet_model(seqlen=2000, num_dilated_convs=9)\n",
    "\n",
    "# flatten and concat outputs\n",
    "inp = tf.keras.Input(shape=model.input_shape[1:])\n",
    "prof, cts = model(inp)\n",
    "prof = tf.keras.layers.Flatten()(prof)\n",
    "cts = tf.keras.layers.Flatten()(cts)\n",
    "out = tf.keras.layers.Concatenate()([prof, cts])\n",
    "model_ig = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "# flattened outputs\n",
    "model = model_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 2001) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 500\tTIME: 622.02\tPER 100: 12440.47\n",
      "BEST PER 100: 12440.47\n"
     ]
    }
   ],
   "source": [
    "time_ig(model, [500], 2000, num_examples=5, targets=range(2001)) # all 2000 profile outs + 1 count out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
