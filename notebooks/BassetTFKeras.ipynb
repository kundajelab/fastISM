{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise ISM for the Basset Architecture\n",
    "\n",
    "Proof of concept in tf/Keras, essentially a copy of the PyTorch notebook. \n",
    "\n",
    "One key difference is this noteobok would forward prop with multiple examples, each having mutation in the same ith regions. This is different compared to the PyTorch notebook, in which each forward prop has the same sequence with mutations at different positions, which made the bookkeeping harder. Inspired by discussions with Av.\n",
    "\n",
    "Architecture (PyTorch): [link](https://github.com/kundajelab/GenoPyT/blob/c84f38dfaa0c986f91383dd7e6278c1cb993498d/src/models/sequence_only/basset.py). Padding changed for last layer since Keras allows 'same' or 'valid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/device:CPU:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idxs_conv_maxpool(seqlen, kernelsize, padding, maxpool_kernel, change_ranges, \n",
    "                          conv_stride=1,\n",
    "                          maxpool_stride=None,\n",
    "                          maxpool_ceil_mode=False): \n",
    "\n",
    "    # assumes stride==1 for conv and stride=kernel for maxpool \n",
    "    # change ranges are BEFORE padding \n",
    "    # indexes returned are slices AFTER padding input seqs\n",
    "    \n",
    "    if maxpool_ceil_mode==True or conv_stride!=1 or maxpool_stride!=None: \n",
    "        # will take extra care, e.g. repeat values in last block  \n",
    "        raise NotImplementedError \n",
    "     \n",
    "    # raw ranges for each change_range -- this is the input range in which\n",
    "    # changing the change_range will affect the output\n",
    "    raw_seq_ranges = [(x-kernelsize+1,y+kernelsize-1) for x,y in change_ranges] \n",
    "     \n",
    "    # re-adjust since there will be `padding` number of zeros in the beginning \n",
    "    raw_seq_pad_adjusted = [(x+padding, y+padding) for x,y in raw_seq_ranges] \n",
    "     \n",
    "    range_corrected = [] \n",
    "    for x,y in raw_seq_pad_adjusted: \n",
    "        # shift around the edges\n",
    "        if x<0 and y>seqlen+2*padding: # kinda degenerate, required when using for fc layers\n",
    "            range_corrected.append((0,seqlen+2*padding))\n",
    "        elif x<0: \n",
    "            range_corrected.append((0, y-x)) \n",
    "        elif y > seqlen+2*padding: \n",
    "            range_corrected.append((x-(y-seqlen-2*padding),seqlen+2*padding)) \n",
    "        else: \n",
    "            range_corrected.append((x,y)) \n",
    "\n",
    "    # the conv output range affected by each input\n",
    "    conv_out_ranges = [(x,y-kernelsize+1) for x,y in range_corrected] \n",
    "\n",
    "    # length of sequence after convolution\n",
    "    conv_seqlen = seqlen + 2*padding - kernelsize + 1\n",
    "    \n",
    "    # shift to the edges of the nearest maxpool block\n",
    "    mod_shifted = [(maxpool_kernel*(x//maxpool_kernel), \n",
    "                   maxpool_kernel*((y-1)//maxpool_kernel+1)) for x,y in conv_out_ranges] \n",
    "    # each should be the same size\n",
    "    maxwidth = max([y-x for x,y in mod_shifted])  \n",
    "\n",
    "    mod_shifted = [(x,x+maxwidth) if y<=conv_seqlen else (y-maxwidth, y) for x,y in mod_shifted]  \n",
    "     \n",
    "    # when ceil_mode==False, this works by ignoring last block [ceil_mode==False also ignores last block]  \n",
    "    mod_shifted = [(x,y) if y<=conv_seqlen else (x-maxpool_kernel,y-maxpool_kernel) for x,y in mod_shifted]  \n",
    "    assert([y<=conv_seqlen for _,y in mod_shifted])  \n",
    "    \n",
    "    # this would be the output ranges AFTER maxpool\n",
    "    out_ranges = [(x//maxpool_kernel, y//maxpool_kernel) for x,y in mod_shifted]  \n",
    "     \n",
    "    # work back input slices for desired output maxpool ranges\n",
    "    slice_ranges = [(x,y+kernelsize-1) for x,y in mod_shifted] \n",
    "    \n",
    "    offsets = [x+padding-slice_ranges[i][0] for i,(x,_) in enumerate(change_ranges)] \n",
    "    \n",
    "    return (slice_ranges, offsets), out_ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUT_POS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "([s_slice], _), [mxp1_out_range] = get_idxs_conv_maxpool(1000, 19, 9, 3, [(MUT_POS,MUT_POS+1)])\n",
    "inp_width = s_slice[1]-s_slice[0]\n",
    "print(inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input sequence \n",
    "with tf.device(device):\n",
    "    inp_seq_np = np.random.randn(1000,1000,4)\n",
    "    inp_seq_np = inp_seq_np.astype(np.float32)\n",
    "    inp_seq_perturbed_np = np.copy(inp_seq_np)\n",
    "    inp_seq_perturbed_np[:, MUT_POS, :] = 0\n",
    "\n",
    "    inp_seq = tf.constant(inp_seq_np)\n",
    "    inp_seq_perturbed = tf.constant(inp_seq_perturbed_np)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_perturbed.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1018, 4])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq = tf.concat([tf.zeros((1000,9,4)), \n",
    "                            inp_seq_perturbed, \n",
    "                            tf.zeros((1000,9,4))], \n",
    "                           axis=1)\n",
    "padded_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 129)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 µs ± 974 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit padded_inp_seq[:, s_slice[0]:s_slice[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1 + Maxpool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = tf.keras.Sequential()\n",
    "l1.add(tf.keras.layers.Conv1D(300, 19, strides=1, padding='valid'))\n",
    "l1.add(tf.keras.layers.BatchNormalization())\n",
    "l1.add(tf.keras.layers.MaxPool1D(3))\n",
    "\n",
    "l1_w_padding = tf.keras.models.clone_model(l1)\n",
    "l1_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l1.build(input_shape=(None,s_slice[1]-s_slice[0],4))\n",
    "l1_w_padding.build(input_shape=(None, 1000, 4))\n",
    "l1_w_padding.layers[0].set_weights(l1.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 7, 300])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out = l1(padded_inp_seq[:, s_slice[0]:s_slice[1], :])\n",
    "mxp1_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1018, 4])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 1000, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq_perturbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 ms ± 36.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l1(padded_inp_seq[:, s_slice[0]:s_slice[1], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 333, 300])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_ism_out = l1_w_padding(inp_seq_perturbed)\n",
    "mxp1_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.3 ms ± 174 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l1_w_padding(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 37)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does not seem to hold for smaller atol (<1e-6) values\n",
    "# same atol value for PyTorch as well\n",
    "np.all(np.isclose(mxp1_out.numpy(), mxp1_ism_out.numpy()[:,range(*mxp1_out_range)], atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 333, 300])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_ref = l1_w_padding(inp_seq)\n",
    "mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "([mxp1_out_slice], [mxp1_out_offset]), [mxp2_out_range] = get_idxs_conv_maxpool(333, 11, 5, 4, [mxp1_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "conv2_inp_width = mxp1_out_slice[1]-mxp1_out_slice[0]\n",
    "print(conv2_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp_num_channels = mxp1_out.shape[2]\n",
    "conv2_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 54)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 11)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 333, 300])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 343, 300])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp1_out_ref = tf.concat([tf.zeros((1000,5,mxp1_out_ref.shape[2])), \n",
    "                            mxp1_out_ref, \n",
    "                            tf.zeros((1000,5,mxp1_out_ref.shape[2]))], \n",
    "                           axis=1)\n",
    "padded_mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 30, 300])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_inp = tf.concat([padded_mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[0]+mxp1_out_offset],\n",
    "                      mxp1_out,\n",
    "                      padded_mxp1_out_ref[:, mxp1_out_slice[0]+mxp1_out_offset+mxp1_out.shape[1]:mxp1_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv2_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2 + Maxpool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = tf.keras.Sequential()\n",
    "l2.add(tf.keras.layers.Conv1D(200, 11, strides=1, padding='valid'))\n",
    "l2.add(tf.keras.layers.BatchNormalization())\n",
    "l2.add(tf.keras.layers.MaxPool1D(4))\n",
    "\n",
    "l2_w_padding = tf.keras.models.clone_model(l2)\n",
    "l2_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l2.build(input_shape=(None,mxp1_out_slice[1]-mxp1_out_slice[0],conv2_inp_num_channels))\n",
    "l2_w_padding.build(input_shape=(None, mxp1_ism_out.shape[1], conv2_inp_num_channels))\n",
    "l2_w_padding.layers[0].set_weights(l2.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 5, 200])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out = l2(conv2_inp)\n",
    "mxp2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    l2(tf.concat([mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[0]+mxp1_out_offset],\n",
    "                      mxp1_out,\n",
    "                      mxp1_out_ref[:, mxp1_out_slice[0]+mxp1_out_offset+mxp1_out.shape[1]:mxp1_out_slice[1]]],\n",
    "                     axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.83 ms ± 179 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 83, 200])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_ism_out = l2_w_padding(mxp1_ism_out)\n",
    "mxp2_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 ms ± 180 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l2_w_padding(mxp1_ism_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(mxp2_out.numpy(), mxp2_ism_out.numpy()[:,range(*mxp2_out_range)], atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 83, 200])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_ref = l2_w_padding(mxp1_out_ref)\n",
    "mxp2_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "([mxp2_out_slice], [mxp2_out_offset]), [mxp3_out_range] = get_idxs_conv_maxpool(83, 7, 3, 4, [mxp2_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "conv3_inp_width = mxp2_out_slice[1]-mxp2_out_slice[0]\n",
    "print(conv3_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp_num_channels = mxp2_out.shape[2]\n",
    "conv3_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 22)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp2_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 89, 200])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp2_out_ref = tf.concat([tf.zeros((1000,3,mxp2_out_ref.shape[2])), \n",
    "                            mxp2_out_ref, \n",
    "                            tf.zeros((1000,3,mxp2_out_ref.shape[2]))], \n",
    "                           axis=1)\n",
    "padded_mxp2_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 22, 200])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_inp = tf.concat([padded_mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[0]+mxp2_out_offset],\n",
    "                      mxp2_out,\n",
    "                      padded_mxp2_out_ref[:, mxp2_out_slice[0]+mxp2_out_offset+mxp2_out.shape[1]:mxp2_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv3_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3 + Maxpool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = tf.keras.Sequential()\n",
    "l3.add(tf.keras.layers.Conv1D(200, 7, strides=1, padding='valid'))\n",
    "l3.add(tf.keras.layers.BatchNormalization())\n",
    "l3.add(tf.keras.layers.MaxPool1D(4))\n",
    "\n",
    "l3_w_padding = tf.keras.models.clone_model(l3)\n",
    "l3_w_padding.layers[0].padding = 'same'\n",
    "\n",
    "l3.build(input_shape=(None,mxp2_out_slice[1]-mxp2_out_slice[0],conv3_inp_num_channels))\n",
    "l3_w_padding.build(input_shape=(None, mxp2_ism_out.shape[1], conv3_inp_num_channels))\n",
    "l3_w_padding.layers[0].set_weights(l3.layers[0].get_weights()) # copy conv weights\n",
    "# not copying batch norm weights for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 4, 200])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out = l3(conv3_inp)\n",
    "mxp3_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    l3(tf.concat([mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[0]+mxp2_out_offset],\n",
    "                      mxp2_out,\n",
    "                      mxp2_out_ref[:, mxp2_out_slice[0]+mxp2_out_offset+mxp2_out.shape[1]:mxp2_out_slice[1]]],\n",
    "                     axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 ms ± 316 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 20, 200])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_ism_out = l3_w_padding(mxp2_ism_out)\n",
    "mxp3_ism_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75 ms ± 5.28 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit l3_w_padding(mxp2_ism_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(mxp3_out.numpy(), mxp3_ism_out.numpy()[:,range(*mxp3_out_range)], atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 20, 200])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_ref = l3_w_padding(mxp2_out_ref)\n",
    "mxp3_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next layer is FC layer, can be treated as conv with filter=width, no padding, no maxpool (maxpool width 1)\n",
    "([mxp3_out_slice], [mxp3_out_offset]), _ = get_idxs_conv_maxpool(20, 20, 0, 1, [mxp3_out_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "conv4_inp_width = mxp3_out_slice[1]-mxp3_out_slice[0]\n",
    "print(conv4_inp_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp_num_channels = mxp3_out.shape[2]\n",
    "conv4_inp_num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mxp3_out_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 20, 200])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4_inp = tf.concat([mxp3_out_ref[:, mxp3_out_slice[0]:mxp3_out_slice[0]+mxp3_out_offset],\n",
    "                      mxp3_out,\n",
    "                      mxp3_out_ref[:, mxp3_out_slice[0]+mxp3_out_offset+mxp3_out.shape[1]:mxp3_out_slice[1]]],\n",
    "                     axis=1)\n",
    "conv4_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with ISM conv3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(conv4_inp.numpy(), mxp3_ism_out.numpy(), atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCs (Fully Connected Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcs = tf.keras.Sequential()\n",
    "fcs.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "fcs.add(tf.keras.layers.BatchNormalization())\n",
    "fcs.add(tf.keras.layers.Dense(1000, activation='relu'))\n",
    "fcs.add(tf.keras.layers.BatchNormalization())\n",
    "fcs.add(tf.keras.layers.Dense(10))\n",
    "fcs.build(input_shape=(None,4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output -> reshape -> fc\n",
    "def f():\n",
    "    fcs(tf.reshape(tf.concat([mxp3_out_ref[:, mxp3_out_slice[0]:mxp3_out_slice[0]+mxp3_out_offset],\n",
    "                      mxp3_out,\n",
    "                      mxp3_out_ref[:, mxp3_out_slice[0]+mxp3_out_offset+mxp3_out.shape[1]:mxp3_out_slice[1]]],\n",
    "                     axis=1),\n",
    "               (-1,4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78 ms ± 217 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only reshape -> fc\n",
    "def f():\n",
    "    fcs(tf.reshape(mxp3_ism_out, (-1,4000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46 ms ± 263 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without optimisations\n",
    "def normalISMModel():\n",
    "    inp = tf.keras.Input(shape=(1000,4))\n",
    "\n",
    "    # conv mxp 1\n",
    "    x = tf.keras.layers.Conv1D(300, 19, strides=1, padding='same', name='conv1')(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    # conv mxp 2\n",
    "    x = tf.keras.layers.Conv1D(200, 11, strides=1, padding='same', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # conv mxp 3\n",
    "    x = tf.keras.layers.Conv1D(200, 7, strides=1, padding='same', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # fc\n",
    "    x = tf.keras.layers.Reshape((4000,))(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(10, name='fc3')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inp, outputs=x, name='normalISM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ISM_model = normalISMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_normal():\n",
    "    return normal_ISM_model(inp_seq_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 ms ± 167 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceAssign(tf.keras.layers.Layer): \n",
    "    def __init__(self, b_dim): \n",
    "        super(SliceAssign, self).__init__() \n",
    "        \n",
    "        # after one slice assign, tf can't calculate dimension \n",
    "        # since i is not known. So manually specify b_dim\n",
    "        self.b_dim = b_dim\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # GOAL: a[:,i:i+b.shape[1]] = b\n",
    "\n",
    "        a, b, i = inputs\n",
    "        # output will lose shape info (dim 1 will be set to None)\n",
    "        return tf.concat([a[:,:i[0]], b, a[:,i[0]+self.b_dim:]], axis=1) \n",
    "    \n",
    "    \n",
    "def fastISMModel():\n",
    "    inp = tf.keras.Input(shape=(inp_width,4))\n",
    "    padded_mxp1_out_ref = tf.keras.Input(shape=(conv2_inp_width, conv2_inp_num_channels))\n",
    "    mxp1_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    padded_mxp2_out_ref = tf.keras.Input(shape=(conv3_inp_width, conv3_inp_num_channels))\n",
    "    mxp2_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    mxp3_out_ref = tf.keras.Input(shape=(conv4_inp_width, conv4_inp_num_channels))\n",
    "    mxp3_out_offset = tf.keras.Input(batch_size=1, shape=(), dtype='int32')\n",
    "    \n",
    "    # conv mxp 1\n",
    "    x = tf.keras.layers.Conv1D(300, 19, strides=1, padding='valid', name='conv1')(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(3)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp1_out_range[1]-mxp1_out_range[0])([padded_mxp1_out_ref, x, mxp1_out_offset])\n",
    "\n",
    "    # conv mxp 2\n",
    "    x = tf.keras.layers.Conv1D(200, 11, strides=1, padding='valid', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp2_out_range[1]-mxp2_out_range[0])([padded_mxp2_out_ref, x, mxp2_out_offset])\n",
    "    \n",
    "    # conv mxp 3\n",
    "    x = tf.keras.layers.Conv1D(200, 7, strides=1, padding='valid', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) \n",
    "    x = tf.keras.layers.MaxPool1D(4)(x)\n",
    "    \n",
    "    # slice assign\n",
    "    x = SliceAssign(mxp3_out_range[1]-mxp3_out_range[0])([mxp3_out_ref, x, mxp3_out_offset])\n",
    "    \n",
    "    # fc\n",
    "    x = tf.keras.layers.Reshape((4000,))(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='fc2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(10, name='fc3')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inp, \n",
    "                                   padded_mxp1_out_ref, mxp1_out_offset,\n",
    "                                   padded_mxp2_out_ref, mxp2_out_offset,\n",
    "                                   mxp3_out_ref, mxp3_out_offset], \n",
    "                           outputs=x, name='fastISM')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_ISM_model = fastISMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs \n",
    "type(padded_mxp1_out_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 39, 4])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inp_seq[:, s_slice[0]:s_slice[1], :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 343, 300])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp1_out_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:GPU:0'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_mxp1_out_ref.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fast():\n",
    "    return fast_ISM_model([padded_inp_seq[:, s_slice[0]:s_slice[1], :],\n",
    "                       padded_mxp1_out_ref[:, mxp1_out_slice[0]:mxp1_out_slice[1]], tf.ones(1)*mxp1_out_offset, \n",
    "                       padded_mxp2_out_ref[:, mxp2_out_slice[0]:mxp2_out_slice[1]], tf.ones(1)*mxp2_out_offset, \n",
    "                       mxp3_out_ref, tf.ones(1)*mxp3_out_offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7 ms ± 73.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run so they build weights if haven't\n",
    "run_normal()\n",
    "run_fast()\n",
    "\n",
    "# set weights to those from initial layers so that tensors like `padded_mxp1_out_ref` can be reused\n",
    "fast_ISM_model.get_layer(\"conv1\").set_weights(l1.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv1\").set_weights(l1.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"conv2\").set_weights(l2.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv2\").set_weights(l2.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"conv3\").set_weights(l3.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"conv3\").set_weights(l3.layers[0].get_weights())\n",
    "\n",
    "# fcs\n",
    "fast_ISM_model.get_layer(\"fc1\").set_weights(fcs.layers[0].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc1\").set_weights(fcs.layers[0].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"fc2\").set_weights(fcs.layers[2].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc2\").set_weights(fcs.layers[2].get_weights())\n",
    "\n",
    "fast_ISM_model.get_layer(\"fc3\").set_weights(fcs.layers[4].get_weights())\n",
    "normal_ISM_model.get_layer(\"fc3\").set_weights(fcs.layers[4].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(run_normal().numpy(), run_fast().numpy(), atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
