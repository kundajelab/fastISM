{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import fastISM\n",
    "from fastISM.models.basset import basset_model\n",
    "\n",
    "from fastISM.models.factorized_basset import factorized_basset_model\n",
    "from fastISM.models.bpnet import bpnet_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fastISM' from '../fastISM/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(fastISM.flatten_model)\n",
    "reload(fastISM.models)\n",
    "reload(fastISM.ism_base)\n",
    "reload(fastISM.change_range)\n",
    "reload(fastISM.fast_ism_utils)\n",
    "reload(fastISM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/device:CPU:0'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "from alibi.explainers import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alibi.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ig(model, batch_sizes, seqlen, num_examples=500, n_steps=50, targets = [None]):\n",
    "    x = np.random.random((num_examples,seqlen,4))\n",
    "    times = []\n",
    "    per_100 = []\n",
    "    for b in batch_sizes:\n",
    "        ig  = IntegratedGradients(model,\n",
    "                              layer=None,\n",
    "                              method=\"gausslegendre\",\n",
    "                              n_steps=n_steps,\n",
    "                              internal_batch_size=b)\n",
    "        # dry run\n",
    "        ig.explain(x[:10], baselines=None,\n",
    "                   target=targets[0])\n",
    "        \n",
    "        t = time.time()\n",
    "        for tgt in targets:\n",
    "            ig.explain(x, baselines=None,\n",
    "                       target=tgt)\n",
    "        times.append(time.time()-t)\n",
    "        per_100.append((times[-1]/num_examples)*100)\n",
    "        print(\"BATCH: {}\\tTIME: {:.2f}\\tPER 100: {:.2f}\".format(b, times[-1], (times[-1]/num_examples)*100))\n",
    "    \n",
    "    print(\"BEST PER 100: {:.2f}\".format(min(per_100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basset_model(seqlen=1000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.37\tPER 100: 3.73\n",
      "BATCH: 200\tTIME: 0.36\tPER 100: 3.61\n",
      "BATCH: 500\tTIME: 0.36\tPER 100: 3.57\n",
      "BEST PER 100: 3.57\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout \n",
    "# hide warning about scalar output\n",
    "\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=10, targets=[None]) # targets None since only one scalar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 3.77\tPER 100: 3.77\n",
      "BATCH: 200\tTIME: 3.64\tPER 100: 3.64\n",
      "BATCH: 500\tTIME: 3.58\tPER 100: 3.58\n",
      "BATCH: 1000\tTIME: 3.59\tPER 100: 3.59\n",
      "BEST PER 100: 3.58\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500, 1000], 1000, num_examples=100, targets=[None]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basset (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basset_model(seqlen=2000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.74\tPER 100: 7.40\n",
      "BATCH: 200\tTIME: 0.72\tPER 100: 7.21\n",
      "BATCH: 500\tTIME: 0.72\tPER 100: 7.18\n",
      "BEST PER 100: 7.18\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500], 2000, num_examples=10, targets=[None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 7.39\tPER 100: 7.39\n",
      "BATCH: 200\tTIME: 7.25\tPER 100: 7.25\n",
      "BATCH: 500\tTIME: 7.26\tPER 100: 7.26\n",
      "BEST PER 100: 7.25\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "time_ig(model, [100, 200, 500], 2000, num_examples=100, targets=[None]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorized Basset (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = factorized_basset_model(seqlen=1000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 0.82\tPER 100: 8.18\n",
      "BATCH: 200\tTIME: 0.80\tPER 100: 8.00\n",
      "BATCH: 500\tTIME: 0.80\tPER 100: 8.04\n",
      "BEST PER 100: 8.00\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=10, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 8.13\tPER 100: 8.13\n",
      "BATCH: 200\tTIME: 7.90\tPER 100: 7.90\n",
      "BATCH: 500\tTIME: 7.97\tPER 100: 7.97\n",
      "BEST PER 100: 7.90\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 500], 1000, num_examples=100, targets=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorized Basset (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = factorized_basset_model(seqlen=2000, num_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 1.60\tPER 100: 16.02\n",
      "BATCH: 200\tTIME: 1.58\tPER 100: 15.77\n",
      "BATCH: 300\tTIME: 1.61\tPER 100: 16.11\n",
      "BEST PER 100: 15.77\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=10, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 16.09\tPER 100: 16.09\n",
      "BATCH: 200\tTIME: 16.01\tPER 100: 16.01\n",
      "BATCH: 300\tTIME: 16.32\tPER 100: 16.32\n",
      "BEST PER 100: 16.01\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=100, targets=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 100\tTIME: 32.41\tPER 100: 16.20\n",
      "BATCH: 200\tTIME: 32.08\tPER 100: 16.04\n",
      "BATCH: 300\tTIME: 32.82\tPER 100: 16.41\n",
      "BEST PER 100: 16.04\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "time_ig(model, [100, 200, 300], 2000, num_examples=200, targets=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPNet (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpnet_model(seqlen=1000, num_dilated_convs=9)\n",
    "\n",
    "# flatten and concat outputs\n",
    "inp = tf.keras.Input(shape=model.input_shape[1:])\n",
    "prof, cts = model(inp)\n",
    "prof = tf.keras.layers.Flatten()(prof)\n",
    "cts = tf.keras.layers.Flatten()(cts)\n",
    "out = tf.keras.layers.Concatenate()([prof, cts])\n",
    "model_ig = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "# flattened outputs\n",
    "model = model_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/concat:0' shape=(None, 1001) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 500\tTIME: 536.40\tPER 100: 5364.00\n",
      "BEST PER 100: 5364.00\n"
     ]
    }
   ],
   "source": [
    "time_ig(model, [500], 1000, num_examples=10, targets=range(1001)) # all 1000 profile outs + 1 count out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPNet (2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bpnet_model(seqlen=2000, num_dilated_convs=9)\n",
    "\n",
    "# flatten and concat outputs\n",
    "inp = tf.keras.Input(shape=model.input_shape[1:])\n",
    "prof, cts = model(inp)\n",
    "prof = tf.keras.layers.Flatten()(prof)\n",
    "cts = tf.keras.layers.Flatten()(cts)\n",
    "out = tf.keras.layers.Concatenate()([prof, cts])\n",
    "model_ig = tf.keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "# flattened outputs\n",
    "model = model_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 2001) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 500\tTIME: 874.62\tPER 100: 17492.43\n",
      "BEST PER 100: 17492.43\n"
     ]
    }
   ],
   "source": [
    "time_ig(model, [500], 2000, num_examples=5, targets=range(2001)) # all 2000 profile outs + 1 count out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
